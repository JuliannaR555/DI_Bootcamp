{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c38319f",
   "metadata": {},
   "source": [
    "## Exercises XP: W2_D2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10c342",
   "metadata": {},
   "source": [
    "### Exercise 1: Identifying Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e83b7",
   "metadata": {},
   "source": [
    "#### Below are various data sources. Identify whether each one is an example of structured or unstructured data.\n",
    "\n",
    "| Data Source                                 | Type         |\n",
    "|---------------------------------------------|--------------|\n",
    "| Excel financial report                      | Structured   |\n",
    "| Social media photos                         | Unstructured |\n",
    "| News articles                               | Unstructured |\n",
    "| Inventory in a relational database          | Structured   |\n",
    "| Market research recorded interviews         | Unstructured |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c604eb0",
   "metadata": {},
   "source": [
    "### Exercise 2: Transformation Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59392ca4",
   "metadata": {},
   "source": [
    "##### For each unstructured source below, I suggested a possible method to convert it into structured data, and explained why.\n",
    "\n",
    "| Unstructured Data Source                       | Method to Convert to Structured Data                                     | Reasoning                                                           |\n",
    "| ---------------------------------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------- |\n",
    "| Blog posts about travel experiences            | Use NLP techniques to extract keywords, topics, sentiment into a table   | Text analysis can turn paragraphs into structured categories        |\n",
    "| Audio recordings of customer service calls     | Apply speech-to-text, then analyze transcripts                           | Transcripts can be parsed into conversation topics, durations, etc. |\n",
    "| Handwritten notes from a brainstorming session | Use OCR (Optical Character Recognition) to extract text                  | Once digitized, text can be organized by idea, category, or author  |\n",
    "| A video tutorial on cooking                    | Extract audio and apply speech-to-text, then tag video segments manually | Allows conversion into step-by-step structured instructions         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96113d41",
   "metadata": {},
   "source": [
    "### Exercise 3 : Import a file from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a83235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Load the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d952e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65810716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Authentification via le fichier kaggle.json déjà placé dans C:\\Users\\julia\\.kaggle\\\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d2aa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/hesh97/titanicdataset-traincsv\n"
     ]
    }
   ],
   "source": [
    "# 2. Télécharger le dataset ZIP dans le dossier courant\n",
    "api.dataset_download_files('hesh97/titanicdataset-traincsv', path='.', unzip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d62a74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier ZIP a été extrait avec succès.\n"
     ]
    }
   ],
   "source": [
    "# 3. Décompresser le fichier zip\n",
    "zip_path = 'titanicdataset-traincsv.zip'\n",
    "if os.path.exists(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')  # Dézippe les fichiers ici\n",
    "    print(\"Le fichier ZIP a été extrait avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90486c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données chargées depuis train.csv :\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# 4. Charger le CSV dans un DataFrame Pandas\n",
    "csv_path = 'train.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"✅ Données chargées depuis train.csv :\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"❌ train.csv introuvable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a5277",
   "metadata": {},
   "source": [
    "### Exercise 4: Importing a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f15f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import pandas library\n",
    "\n",
    "# Read the iris.csv file (make sure it's in the same folder as your notebook/script)\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# Display the first five rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6d47c",
   "metadata": {},
   "source": [
    "### Exercise 5 : Export a dataframe to excel format and JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5718a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age    City\n",
      "0    Alice   25   Paris\n",
      "1      Bob   30  London\n",
      "2  Charlie   35  Berlin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import pandas\n",
    "\n",
    "# Create a simple dataframe\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['Paris', 'London', 'Berlin']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Export the dataframe to an Excel file\n",
    "df.to_excel(\"people.xlsx\", index=False)  # index=False to avoid writing row numbers\n",
    "\n",
    "# Export the dataframe to a JSON file\n",
    "df.to_json(\"people.json\", orient=\"records\", indent=4)  # formatted JSON output\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5903651",
   "metadata": {},
   "source": [
    "### Exercise 6: Reading JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "019c2671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id              name   username                      email  \\\n",
      "0   1     Leanne Graham       Bret          Sincere@april.biz   \n",
      "1   2      Ervin Howell  Antonette          Shanna@melissa.tv   \n",
      "2   3  Clementine Bauch   Samantha         Nathan@yesenia.net   \n",
      "3   4  Patricia Lebsack   Karianne  Julianne.OConner@kory.org   \n",
      "4   5  Chelsey Dietrich     Kamren   Lucio_Hettinger@annie.ca   \n",
      "\n",
      "                                             address                  phone  \\\n",
      "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
      "1  {'street': 'Victor Plains', 'suite': 'Suite 87...    010-692-6593 x09125   \n",
      "2  {'street': 'Douglas Extension', 'suite': 'Suit...         1-463-123-4447   \n",
      "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
      "4  {'street': 'Skiles Walks', 'suite': 'Suite 351...          (254)954-1289   \n",
      "\n",
      "         website                                            company  \n",
      "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
      "1  anastasia.net  {'name': 'Deckow-Crist', 'catchPhrase': 'Proac...  \n",
      "2    ramiro.info  {'name': 'Romaguera-Jacobson', 'catchPhrase': ...  \n",
      "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
      "4   demarco.info  {'name': 'Keebler LLC', 'catchPhrase': 'User-c...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import pandas\n",
    "\n",
    "# Load JSON data from a URL\n",
    "url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "\n",
    "# Read the JSON data into a DataFrame\n",
    "df = pd.read_json(url)\n",
    "\n",
    "# Display the first five entries\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
