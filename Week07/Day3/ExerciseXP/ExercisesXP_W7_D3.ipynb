{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362f7dd7",
   "metadata": {},
   "source": [
    "## Exercises XP: W7_D3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70f6df",
   "metadata": {},
   "source": [
    "#### What You’ll Learn\n",
    "\n",
    "- **Practical LLM Evaluation:** Gain hands-on experience evaluating LLMs for summarization.  \n",
    "- **Metric Deep Dive:** Understand the strengths and weaknesses of various evaluation metrics (accuracy, ROUGE).  \n",
    "- **Model Comparison:** Learn to systematically compare different LLMs and model sizes.  \n",
    "- **Hugging Face Proficiency:** Enhance your skills in using Hugging Face’s *transformers* and *evaluate* libraries.  \n",
    "- **Customization:** Implement and analyze the effects of modifying evaluation metrics and model parameters.  \n",
    "- **Data Handling:** Learn how to load, process, and sample text datasets using pandas.  \n",
    "- **Text Preprocessing:** Understand the importance of text preprocessing for NLP tasks.  \n",
    "- **Debugging and Analysis:** Develop skills in debugging and analyzing LLM outputs.  \n",
    "\n",
    "---\n",
    "\n",
    "#### What You Will Create\n",
    "\n",
    "- **Evaluation Scripts:** Python scripts to calculate and compare summarization metrics.  \n",
    "- **Comparative Reports:** DataFrames and visualizations summarizing the performance of different LLMs.  \n",
    "- **Modified Evaluation Metrics:** Custom accuracy metrics tailored for summarization.  \n",
    "- **Summarization Outputs:** Generated summaries from various LLMs for comparative analysis.  \n",
    "- **Analytical Reports:** Documentation of findings, including discussions on metric behavior and model performance.  \n",
    "- **Custom Functions:** Functions to load datasets, generate summaries, and compute ROUGE scores.  \n",
    "- **Model Comparison Tables:** Tables comparing performance of different LLMs across various metrics.  \n",
    "\n",
    "---\n",
    "\n",
    "All of today’s exercises are part of a single, hands-on tutorial designed to teach you how to evaluate LLMs on summarization tasks. Together, you will:\n",
    "\n",
    "- Measure accuracy on summary outputs  \n",
    "- Compute ROUGE-N scores  \n",
    "- Build a consistent framework for comparing different model sizes and architectures  \n",
    "\n",
    "Each part builds on the last, giving you a cohesive workflow for assessing and contrasting summarization performance.\n",
    "\n",
    "---\n",
    "\n",
    "# Learning Objectives\n",
    "\n",
    "- **Metric Understanding:** Learn to compute ROUGE-N and understand its nuances.  \n",
    "- **Intuition Building:** Develop an intuitive understanding of ROUGE-N and its application to summarization.  \n",
    "- **Comparative Analysis:** Test and compare various LLMs and model sizes on a consistent dataset.  \n",
    "\n",
    "#### Part II: Dataset Loading and Exploration\n",
    "\n",
    "- **Dataset Loading:** Load the *train.csv* and *test.csv* datasets using pandas.  \n",
    "- **Sampling:** Take a smaller sample of the datasets (e.g., 100 samples from train, 50 from test) to reduce computational load.  \n",
    "- **Exploration:** Display the first example from the training sample, showing the article (*prompt_text*) and its reference summary (*prompt_title*).  \n",
    "- **Data Inspection:** Print the sampled train and test DataFrames to understand the dataset structure.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part III: Summarization with T5\n",
    "\n",
    "- **Function Implementation:** Implement the *summarize_with_t5* function:\n",
    "  - Use *T5ForConditionalGeneration* and *AutoTokenizer* from *transformers*.\n",
    "  - Handle CUDA availability for GPU acceleration.\n",
    "  - Implement batch processing using the *batch_generator* function.\n",
    "  - Tokenize input articles with a “summarize: ” prefix.\n",
    "  - Generate summaries using *model.generate()*.\n",
    "  - Decode generated token IDs back to text.\n",
    "  - Clear CUDA cache (*torch.cuda.empty_cache()*) and garbage collect (*gc.collect()*) after each batch and at the end of the function.\n",
    "- **Summary Generation:** Generate summaries for the training sample using **t5-small**.\n",
    "- **Result Display:** Display the generated summaries alongside the reference summaries in a pandas DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part IV: Accuracy Evaluation\n",
    "\n",
    "- **Accuracy Calculation:** Calculate the accuracy of the **t5-small** summaries by comparing them to the reference summaries.  \n",
    "- **Result Interpretation:** Print the calculated accuracy. Discuss why the accuracy is likely to be very low or zero, reinforcing the limitations of this metric.\n",
    "\n",
    "#### Part V: ROUGE Metric Implementation\n",
    "\n",
    "- **Metric Introduction:** Introduce **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** as a standard metric for summarization.  \n",
    "- **Library Usage:** Load the ROUGE evaluation metric using *evaluate.load(\"rouge\")*.  \n",
    "- **Preprocessing:** Explain the need to format the input summaries with newlines between sentences, and the use of the NLTK sentence tokenizer.  \n",
    "- **Function Definition:** Create the *compute_rouge_score* function to calculate ROUGE scores, handling the necessary preprocessing.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part VI: Understanding ROUGE Scores\n",
    "\n",
    "- **Exact Match Test:** Calculate ROUGE scores when the generated summaries are identical to the reference summaries.  \n",
    "- **Null Prediction Test:** Calculate ROUGE scores when the generated summaries are empty.  \n",
    "- **Stemming Effect:** Demonstrate the impact of stemming on ROUGE scores using simple examples.  \n",
    "- **N-gram Analysis:** Explore how ROUGE-1 and ROUGE-2 scores change with varying degrees of overlap between generated and reference summaries.  \n",
    "- **Symmetry:** Show the symmetry of ROUGE score with respect to predictions and references.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part VII: Comparing Small and Large Models\n",
    "\n",
    "- **Model Selection:** Choose **t5-small**, **t5-base**, and **gpt2** models.  \n",
    "- **Summary Generation:** Generate summaries for the training sample using each model.  \n",
    "- **ROUGE Calculation:** Calculate ROUGE scores for each model’s summaries using *compute_rouge_score*.  \n",
    "- **Per-Row ROUGE:** Create the *compute_rouge_per_row* function to calculate and store ROUGE scores for each individual article in a DataFrame.  \n",
    "- **Result Display:** Display the per-row ROUGE scores for each model.  \n",
    "- **GPT2 Specifics:** Implement the *summarize_with_gpt2* function, handling the “TL;DR:” prompt, and the token length limitations.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part VIII: Comparing All Models\n",
    "\n",
    "- **Aggregation Function:** Create the *compare_models* function to aggregate ROUGE scores for all models into a single DataFrame, showing average scores.  \n",
    "- **Summary Comparison Function:** Create the *compare_models_summaries* function to display the generated summaries from all models side-by-side in a DataFrame.  \n",
    "- **Result Display:** Display the aggregated ROUGE scores and the side-by-side summary comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47651481",
   "metadata": {},
   "source": [
    "### Part I. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cf356",
   "metadata": {},
   "source": [
    "#### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install rouge_score==0.1.2\n",
    "!pip install evaluate\n",
    "!pip install -U accelerate --quiet\n",
    "!pip install datasets\n",
    "!pip install nltk\n",
    "!pip install hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d938ecc",
   "metadata": {},
   "source": [
    "#### Download NLTK Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b27e95",
   "metadata": {},
   "source": [
    "### Part II : Dataset Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50c9bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from evaluate import load\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Xet Storage is enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830bf087",
   "metadata": {},
   "source": [
    "#### Load CNN/DailyMail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c621cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.', 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\", 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}\n"
     ]
    }
   ],
   "source": [
    "# Load the latest version (3.0.0)\n",
    "dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "# Access splits\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# Display first example\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc90d7a",
   "metadata": {},
   "source": [
    "#### Convert to pandas DataFrame with expected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         prompt_text  \\\n",
      "0  LONDON, England (Reuters) -- Harry Potter star...   \n",
      "1  Editor's note: In our Behind the Scenes series...   \n",
      "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
      "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
      "4  (CNN)  -- The National Football League has ind...   \n",
      "\n",
      "                                        prompt_title  \n",
      "0  Harry Potter star Daniel Radcliffe gets £20M f...  \n",
      "1  Mentally ill inmates in Miami are housed on th...  \n",
      "2  NEW: \"I thought I was going to die,\" driver sa...  \n",
      "3  Five small polyps found during procedure; \"non...  \n",
      "4  NEW: NFL chief, Atlanta Falcons owner critical...  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    \"prompt_text\": train_dataset[\"article\"],\n",
    "    \"prompt_title\": train_dataset[\"highlights\"]\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"prompt_text\": test_dataset[\"article\"],\n",
    "    \"prompt_title\": test_dataset[\"highlights\"]\n",
    "})\n",
    "\n",
    "# Show first rows\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e84268",
   "metadata": {},
   "source": [
    "#### Sampling train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e436aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article (prompt_text):\n",
      " Nasa has warned of an impending asteroid pass - and says it will be the closest until 2027. The asteroid, designated 2004 BL86, will safely pass about three times the distance of Earth to the moon on January 26. It will be the closest by any known space rock this large until asteroid 1999 AN10 flies past Earth in 2027. See the Asteroid's route below . At the time of its closest approach on January 26, the asteroid will be approximately 745,000 miles (1.2 million kilometers) from Earth. Due to its orbit around the sun, the asteroid is currently only visible by astronomers with large telescopes who are located in the southern hemisphere. But by Jan. 26, the space rock's changing position will make it visible to those in the northern hemisphere. From its reflected brightness, astronomers estimate that the asteroid is about a third of a mile (0.5 kilometers) in size. At the time of its closest approach on January 26, the asteroid will be approximately 745,000 miles (1.2 million kilometers) from Earth. 'Monday, January 26 will be the closest asteroid 2004 BL86 will get to Earth for at least the next 200 years,' said Don Yeomans, who is retiring as manager of NASA's Near Earth Object Program Office at the Jet Propulsion Laboratory in Pasadena, California, after 16 years in the position. 'And while it poses no threat to Earth for the foreseeable future, it's a relatively close approach by a relatively large asteroid, so it provides us a unique opportunity to observe and learn more.' One way NASA scientists plan to learn more about 2004 BL86 is to observe it with microwaves. NASA's Deep Space Network antenna at Goldstone, California, and the Arecibo Observatory in Puerto Rico will attempt to acquire science data and radar-generated images of the asteroid during the days surrounding its closest approach to Earth. 'When we get our radar data back the day after the flyby, we will have the first detailed images,' said radar astronomer Lance Benner of JPL, the principal investigator for the Goldstone radar observations of the asteroid. 'At present, we know almost nothing about the asteroid, so there are bound to be surprises.' Don't Panic! Nasa says 'While it poses no threat to Earth for the foreseeable future, it's a relatively close approach by a relatively large asteroid, so it provides us a unique opportunity to observe and learn more.' Asteroid 2004 BL86 was initially discovered on Jan. 30, 2004 by a telescope of the Lincoln Near-Earth Asteroid Research (LINEAR) survey in White Sands, New Mexico. The asteroid is expected to be observable to amateur astronomers with small telescopes and strong binoculars. 'I may grab my favorite binoculars and give it a shot myself,' said Yeomans. 'Asteroids are something special. Not only did asteroids provide Earth with the building blocks of life and much of its water, but in the future, they will become valuable resources for mineral ores and other vital natural resources. 'They will also become the fueling stops for humanity as we continue to explore our solar system. There is something about asteroids that makes me want to look up.'\n",
      "\n",
      "Reference Summary (prompt_title):\n",
      " 2004 BL86 will pass about three times the distance of Earth to the moon .\n",
      "Estimate that the asteroid is about a third of a mile (0.5 kilometers) in size .\n",
      "Nasa says it poses no threat to Earth 'for the foreseeable future'\n",
      "\n",
      "Train sample shape: (100, 2)\n",
      "                                         prompt_text  \\\n",
      "0  Nasa has warned of an impending asteroid pass ...   \n",
      "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...   \n",
      "2  By . David Kent . Andy Carroll has taken an un...   \n",
      "3  Los Angeles (CNN) -- Los Angeles has long been...   \n",
      "4  London (CNN) -- Few shows can claim such an au...   \n",
      "\n",
      "                                        prompt_title  \n",
      "0  2004 BL86 will pass about three times the dist...  \n",
      "1  Iraqi Islamic Party calls Quran incident \"blat...  \n",
      "2  Carroll takes to Instagram to post selfie ahea...  \n",
      "3  Pop stars from all over Europe are setting the...  \n",
      "4  NEW: Young athletes light the Olympic cauldron...  \n",
      "\n",
      "Test sample shape: (50, 2)\n",
      "                                         prompt_text  \\\n",
      "0  Down Augusta way they say the azaleas are in f...   \n",
      "1  There was no special treatment for Lewis Fergu...   \n",
      "2  When emergency crews received a call saying 's...   \n",
      "3  A loving boyfriend has granted his girlfriend ...   \n",
      "4  (CNN)Sunday's announcement that Corinthian Col...   \n",
      "\n",
      "                                        prompt_title  \n",
      "0  Justin Rose bounced back from Florida misery b...  \n",
      "1  Lewis Ferguson fell from Merrion Square at Win...  \n",
      "2  Woman reported 'someone' had been run over, bu...  \n",
      "3  Guo Kai and girlfriend Dong Hui, 22, had plann...  \n",
      "4  David Wheeler: Corinthian, considered a \"preda...  \n"
     ]
    }
   ],
   "source": [
    "# Sample 100 rows from train, 50 rows from test\n",
    "train_sample = train_df.sample(100, random_state=42).reset_index(drop=True)\n",
    "test_sample = test_df.sample(50, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display first example from train sample\n",
    "print(\"Article (prompt_text):\\n\", train_sample.loc[0, \"prompt_text\"])\n",
    "print(\"\\nReference Summary (prompt_title):\\n\", train_sample.loc[0, \"prompt_title\"])\n",
    "\n",
    "# Display sampled DataFrames\n",
    "print(\"\\nTrain sample shape:\", train_sample.shape)\n",
    "print(train_sample.head())\n",
    "\n",
    "print(\"\\nTest sample shape:\", test_sample.shape)\n",
    "print(test_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a8cab",
   "metadata": {},
   "source": [
    "### Part III : Summarization with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_t5(texts, model_name=\"t5-small\", batch_size=4, max_length=100):\n",
    "    \"\"\"\n",
    "    Generate summaries for a list of texts using a T5 model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        # Add summarize prefix\n",
    "        inputs = [\"summarize: \" + text for text in batch_texts]\n",
    "\n",
    "        # Tokenize\n",
    "        inputs_tokenized = tokenizer(\n",
    "            inputs,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Generate summaries\n",
    "        outputs = model.generate(\n",
    "            **inputs_tokenized,\n",
    "            max_length=max_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode summaries\n",
    "        decoded_summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outputs]\n",
    "        summaries.extend(decoded_summaries)\n",
    "\n",
    "        # Clear GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614408c7",
   "metadata": {},
   "source": [
    "#### Generate summaries with T5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e6061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c61f793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>generated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nasa has warned of an impending asteroid pass ...</td>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "      <td>the asteroid, designated 2004 BL86, will pass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...</td>\n",
       "      <td>Iraqi Islamic Party calls Quran incident \"blat...</td>\n",
       "      <td>a sniper section leader used a Quran for targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By . David Kent . Andy Carroll has taken an un...</td>\n",
       "      <td>Carroll takes to Instagram to post selfie ahea...</td>\n",
       "      <td>the striker is out for four months after teari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- Los Angeles has long been...</td>\n",
       "      <td>Pop stars from all over Europe are setting the...</td>\n",
       "      <td>aspiring pop stars from the u.s. and abroad ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London (CNN) -- Few shows can claim such an au...</td>\n",
       "      <td>NEW: Young athletes light the Olympic cauldron...</td>\n",
       "      <td>a billion people around the world would be glu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         prompt_text  \\\n",
       "0  Nasa has warned of an impending asteroid pass ...   \n",
       "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...   \n",
       "2  By . David Kent . Andy Carroll has taken an un...   \n",
       "3  Los Angeles (CNN) -- Los Angeles has long been...   \n",
       "4  London (CNN) -- Few shows can claim such an au...   \n",
       "\n",
       "                                        prompt_title  \\\n",
       "0  2004 BL86 will pass about three times the dist...   \n",
       "1  Iraqi Islamic Party calls Quran incident \"blat...   \n",
       "2  Carroll takes to Instagram to post selfie ahea...   \n",
       "3  Pop stars from all over Europe are setting the...   \n",
       "4  NEW: Young athletes light the Olympic cauldron...   \n",
       "\n",
       "                                   generated_summary  \n",
       "0  the asteroid, designated 2004 BL86, will pass ...  \n",
       "1  a sniper section leader used a Quran for targe...  \n",
       "2  the striker is out for four months after teari...  \n",
       "3  aspiring pop stars from the u.s. and abroad ar...  \n",
       "4  a billion people around the world would be glu...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate summaries for the training sample\n",
    "generated_summaries = summarize_with_t5(train_sample[\"prompt_text\"].tolist(), model_name=\"t5-small\")\n",
    "\n",
    "# Combine generated summaries and reference summaries into a DataFrame\n",
    "results_df = train_sample.copy()\n",
    "results_df[\"generated_summary\"] = generated_summaries\n",
    "\n",
    "# Display first rows\n",
    "results_df[[\"prompt_text\", \"prompt_title\", \"generated_summary\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6156f4",
   "metadata": {},
   "source": [
    "### Part IV : Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5a1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(reference_summaries, generated_summaries):\n",
    "    \"\"\"\n",
    "    Calculate simple accuracy: percentage of exact matches between reference and generated summaries.\n",
    "    \"\"\"\n",
    "    matches = sum(1 for ref, gen in zip(reference_summaries, generated_summaries) if ref.strip() == gen.strip())\n",
    "    return matches / len(reference_summaries)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score = calculate_accuracy(train_sample[\"prompt_title\"], results_df[\"generated_summary\"])\n",
    "print(\"Accuracy Score:\", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7765c46",
   "metadata": {},
   "source": [
    "#### Accuracy Score Interpretation\n",
    "\n",
    "The accuracy score is 0.0 because accuracy requires exact string matches between the generated summaries and the reference summaries.  \n",
    "\n",
    "In summarization tasks, even if the generated summary is correct, it is unlikely to be identical to the human-written summary — small differences in phrasing, synonyms, or sentence structure result in an accuracy of 0.  \n",
    "\n",
    "This demonstrates why accuracy is not a useful metric for summarization and why metrics like ROUGE are preferred, as they measure partial overlaps rather than exact matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff20884",
   "metadata": {},
   "source": [
    "### Part V : ROUGE Metric Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba2628c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec7e38dc1c64cffae840abd14adf4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load ROUGE metric\n",
    "rouge_metric = load(\"rouge\")\n",
    "\n",
    "def compute_rouge_score(references, predictions):\n",
    "    \"\"\"\n",
    "    Compute ROUGE-1, ROUGE-2, and ROUGE-L scores between reference and predicted summaries.\n",
    "    Handles preprocessing with sentence tokenization and newline joining.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess: join sentences with newline for ROUGE\n",
    "    references_processed = [\"\\n\".join(sent_tokenize(ref)) for ref in references]\n",
    "    predictions_processed = [\"\\n\".join(sent_tokenize(pred)) for pred in predictions]\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    scores = rouge_metric.compute(\n",
    "        predictions=predictions_processed,\n",
    "        references=references_processed,\n",
    "        use_stemmer=True\n",
    "    )\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab595351",
   "metadata": {},
   "source": [
    "#### Preprocessing for ROUGE\n",
    "\n",
    "ROUGE expects summaries to be split by newlines between sentences.  \n",
    "We use *nltk.sent_tokenize()* to segment each summary into sentences, then join them with *\"\\n\"*.  \n",
    "This ensures that ROUGE correctly counts overlapping n-grams across sentence boundaries and gives more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c616fd5",
   "metadata": {},
   "source": [
    "#### Compute ROUGE scores for T5 summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b4fce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.3651971923063798\n",
      "ROUGE-2: 0.1707697237185407\n",
      "ROUGE-L: 0.26830679191874074\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROUGE between generated summaries and reference summaries\n",
    "rouge_scores = compute_rouge_score(\n",
    "    train_sample[\"prompt_title\"].tolist(),\n",
    "    results_df[\"generated_summary\"].tolist()\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"ROUGE-1:\", rouge_scores[\"rouge1\"])\n",
    "print(\"ROUGE-2:\", rouge_scores[\"rouge2\"])\n",
    "print(\"ROUGE-L:\", rouge_scores[\"rougeL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f7a191",
   "metadata": {},
   "source": [
    "#### ROUGE Score Interpretation\n",
    "\n",
    "- **ROUGE-1 (0.36):** About 36% overlap in unigrams (single words) between generated and reference summaries.\n",
    "- **ROUGE-2 (0.17):** About 17% overlap in bigrams (two-word sequences).\n",
    "- **ROUGE-L (0.26):** About 26% overlap in the longest common subsequence.\n",
    "\n",
    "These scores are typical for abstractive summarization models like T5-small on CNN/DailyMail.  \n",
    "ROUGE provides a more informative evaluation than accuracy, as it rewards partial matches and overlap of key information rather than exact string matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c950c",
   "metadata": {},
   "source": [
    "### Part VI : Understanding ROUGE Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741af62d",
   "metadata": {},
   "source": [
    "#### 1. Exact Match Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41de043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Test: {'rouge1': np.float64(1.0), 'rouge2': np.float64(1.0), 'rougeL': np.float64(1.0), 'rougeLsum': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "ref = [\"The cat is on the mat.\"]\n",
    "pred = [\"The cat is on the mat.\"]\n",
    "\n",
    "scores_exact = compute_rouge_score(ref, pred)\n",
    "print(\"Exact Match Test:\", scores_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba417f",
   "metadata": {},
   "source": [
    "#### 2. Null Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f1a0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Prediction Test: {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n"
     ]
    }
   ],
   "source": [
    "ref = [\"The cat is on the mat.\"]\n",
    "pred = [\"\"]\n",
    "\n",
    "scores_null = compute_rouge_score(ref, pred)\n",
    "print(\"Null Prediction Test:\", scores_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ed893",
   "metadata": {},
   "source": [
    "#### 3. Stemming Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dc00f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming Effect Test: {'rouge1': np.float64(0.6666666666666665), 'rouge2': np.float64(0.28571428571428575), 'rougeL': np.float64(0.6666666666666665), 'rougeLsum': np.float64(0.6666666666666665)}\n"
     ]
    }
   ],
   "source": [
    "ref = [\"The cats are running quickly.\"]\n",
    "pred = [\"The cat runs quick.\"]\n",
    "\n",
    "scores_stemming = compute_rouge_score(ref, pred)\n",
    "print(\"Stemming Effect Test:\", scores_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260517aa",
   "metadata": {},
   "source": [
    "#### 4. N-gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3381059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram Analysis Test: {'rouge1': np.float64(0.75), 'rouge2': np.float64(0.28571428571428575), 'rougeL': np.float64(0.75), 'rougeLsum': np.float64(0.75)}\n"
     ]
    }
   ],
   "source": [
    "ref = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "pred = [\"The quick fox leaps over the dog.\"]\n",
    "\n",
    "scores_ngram = compute_rouge_score(ref, pred)\n",
    "print(\"N-gram Analysis Test:\", scores_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8421338",
   "metadata": {},
   "source": [
    "#### 5. Symmetry Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8524d54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetry Test (Ref→Pred): {'rouge1': np.float64(0.8571428571428571), 'rouge2': np.float64(0.6666666666666666), 'rougeL': np.float64(0.7142857142857143), 'rougeLsum': np.float64(0.7142857142857143)}\n",
      "Symmetry Test (Pred→Ref): {'rouge1': np.float64(0.8571428571428571), 'rouge2': np.float64(0.6666666666666666), 'rougeL': np.float64(0.7142857142857143), 'rougeLsum': np.float64(0.7142857142857143)}\n"
     ]
    }
   ],
   "source": [
    "ref = [\"A summary about climate change and global warming.\"]\n",
    "pred = [\"Climate change and global warming summary.\"]\n",
    "\n",
    "scores_symmetry_1 = compute_rouge_score(ref, pred)\n",
    "scores_symmetry_2 = compute_rouge_score(pred, ref)\n",
    "\n",
    "print(\"Symmetry Test (Ref→Pred):\", scores_symmetry_1)\n",
    "print(\"Symmetry Test (Pred→Ref):\", scores_symmetry_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc29bf5",
   "metadata": {},
   "source": [
    "#### Understanding ROUGE Score Behavior\n",
    "\n",
    "**1. Exact Match Test:**  \n",
    "ROUGE-1, ROUGE-2, and ROUGE-L are 1.0 when the prediction exactly matches the reference.  \n",
    "This confirms that ROUGE gives a perfect score for identical summaries.\n",
    "\n",
    "**2. Null Prediction Test:**  \n",
    "ROUGE scores are 0.0 when the prediction is empty.  \n",
    "This indicates no overlap, which is expected.\n",
    "\n",
    "**3. Stemming Effect Test:**  \n",
    "ROUGE-1 and ROUGE-L are around 0.66, and ROUGE-2 is 0.28.  \n",
    "The use of stemming allows partial credit for related word forms (e.g., \"cats\" vs \"cat\", \"running\" vs \"runs\").\n",
    "\n",
    "**4. N-gram Analysis Test:**  \n",
    "ROUGE-1 is higher (0.75) while ROUGE-2 is lower (0.28).  \n",
    "This shows that unigram overlap is common, but bigram overlap is harder to achieve and provides a stricter measure.\n",
    "\n",
    "**5. Symmetry Test:**  \n",
    "ROUGE scores are the same whether we compare Ref→Pred or Pred→Ref.  \n",
    "This demonstrates that ROUGE is symmetric, meaning it treats both texts equally during comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02985018",
   "metadata": {},
   "source": [
    "### Part VII : Comparing Small and Large Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb0bf1",
   "metadata": {},
   "source": [
    "#### Generate summaries with T5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1a5eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfed3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>generated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nasa has warned of an impending asteroid pass ...</td>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...</td>\n",
       "      <td>Iraqi Islamic Party calls Quran incident \"blat...</td>\n",
       "      <td>u.s. soldier's desecration of the holy book re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By . David Kent . Andy Carroll has taken an un...</td>\n",
       "      <td>Carroll takes to Instagram to post selfie ahea...</td>\n",
       "      <td>england striker posts glum-looking selfie in h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- Los Angeles has long been...</td>\n",
       "      <td>Pop stars from all over Europe are setting the...</td>\n",
       "      <td>singers from all over Europe and farther east ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London (CNN) -- Few shows can claim such an au...</td>\n",
       "      <td>NEW: Young athletes light the Olympic cauldron...</td>\n",
       "      <td>\"Isles of Wonder\" features tributes to the Bri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         prompt_text  \\\n",
       "0  Nasa has warned of an impending asteroid pass ...   \n",
       "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...   \n",
       "2  By . David Kent . Andy Carroll has taken an un...   \n",
       "3  Los Angeles (CNN) -- Los Angeles has long been...   \n",
       "4  London (CNN) -- Few shows can claim such an au...   \n",
       "\n",
       "                                        prompt_title  \\\n",
       "0  2004 BL86 will pass about three times the dist...   \n",
       "1  Iraqi Islamic Party calls Quran incident \"blat...   \n",
       "2  Carroll takes to Instagram to post selfie ahea...   \n",
       "3  Pop stars from all over Europe are setting the...   \n",
       "4  NEW: Young athletes light the Olympic cauldron...   \n",
       "\n",
       "                                   generated_summary  \n",
       "0  2004 BL86 will pass about three times the dist...  \n",
       "1  u.s. soldier's desecration of the holy book re...  \n",
       "2  england striker posts glum-looking selfie in h...  \n",
       "3  singers from all over Europe and farther east ...  \n",
       "4  \"Isles of Wonder\" features tributes to the Bri...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate summaries for the training sample using t5-base\n",
    "generated_summaries_t5_base = summarize_with_t5(\n",
    "    train_sample[\"prompt_text\"].tolist(),\n",
    "    model_name=\"t5-base\"\n",
    ")\n",
    "\n",
    "# Stocker dans un DataFrame pour comparaison\n",
    "results_df_t5_base = train_sample.copy()\n",
    "results_df_t5_base[\"generated_summary\"] = generated_summaries_t5_base\n",
    "\n",
    "# Aperçu\n",
    "results_df_t5_base[[\"prompt_text\", \"prompt_title\", \"generated_summary\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba214c1c",
   "metadata": {},
   "source": [
    "#### 2. Calculer les scores ROUGE pour T5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fd522f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.4037968138277834\n",
      "ROUGE-2: 0.20489791582622335\n",
      "ROUGE-L: 0.2974758003233011\n"
     ]
    }
   ],
   "source": [
    "rouge_scores_t5_base = compute_rouge_score(\n",
    "    train_sample[\"prompt_title\"].tolist(),\n",
    "    results_df_t5_base[\"generated_summary\"].tolist()\n",
    ")\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_scores_t5_base[\"rouge1\"])\n",
    "print(\"ROUGE-2:\", rouge_scores_t5_base[\"rouge2\"])\n",
    "print(\"ROUGE-L:\", rouge_scores_t5_base[\"rougeL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb9648",
   "metadata": {},
   "source": [
    "#### ROUGE Score Interpretation for T5-base\n",
    "\n",
    "- **ROUGE-1 (0.40):** About 40% overlap in unigrams (single words) between the generated summaries and the reference summaries.  \n",
    "- **ROUGE-2 (0.20):** About 20% overlap in bigrams (two-word sequences), showing that some short phrases are captured correctly.  \n",
    "- **ROUGE-L (0.29):** About 29% overlap in the longest common subsequence, indicating that the generated summaries follow the structure of the reference summaries more closely than T5-small.\n",
    "\n",
    "These results are higher than those of T5-small, which suggests that the larger T5-base model captures more relevant details and preserves more accurate phrasing.  \n",
    "However, the scores are still moderate, meaning that there is room for improvement, possibly through fine-tuning or using even larger models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1b58e8",
   "metadata": {},
   "source": [
    "#### Generate summaries with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c8107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def summarize_with_gpt2(texts, model_name=\"gpt2\", max_length=100, batch_size=2):\n",
    "    \"\"\"\n",
    "    Generate summaries using GPT-2 with TL;DR: prompting.\n",
    "    Uses max_new_tokens to avoid input length conflicts.\n",
    "    \"\"\"\n",
    "    # Load model and tokenizer\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    \n",
    "    # GPT-2 has no pad token, set EOS token as pad\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        # Add TL;DR: prompt\n",
    "        inputs = [text + \"\\nTL;DR:\" for text in batch_texts]\n",
    "\n",
    "        # Tokenize inputs\n",
    "        inputs_tokenized = tokenizer(\n",
    "            inputs,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "\n",
    "        # Generate outputs (using max_new_tokens instead of max_length)\n",
    "        outputs = model.generate(\n",
    "            **inputs_tokenized,\n",
    "            max_new_tokens=max_length,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode and post-process\n",
    "        decoded_summaries = [\n",
    "            tokenizer.decode(ids, skip_special_tokens=True).split(\"TL;DR:\")[-1].strip()\n",
    "            for ids in outputs\n",
    "        ]\n",
    "        summaries.extend(decoded_summaries)\n",
    "\n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries_gpt2 = summarize_with_gpt2(\n",
    "    train_sample[\"prompt_text\"].tolist(),\n",
    "    model_name=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46856ea",
   "metadata": {},
   "source": [
    "#### Compute ROUGE for GPT-2 summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "796cd2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>generated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nasa has warned of an impending asteroid pass ...</td>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "      <td>Nasa has warned of an impending asteroid pass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...</td>\n",
       "      <td>Iraqi Islamic Party calls Quran incident \"blat...</td>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By . David Kent . Andy Carroll has taken an un...</td>\n",
       "      <td>Carroll takes to Instagram to post selfie ahea...</td>\n",
       "      <td>By . David Kent . Andy Carroll has taken an un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- Los Angeles has long been...</td>\n",
       "      <td>Pop stars from all over Europe are setting the...</td>\n",
       "      <td>Los Angeles (CNN) -- Los Angeles has long been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London (CNN) -- Few shows can claim such an au...</td>\n",
       "      <td>NEW: Young athletes light the Olympic cauldron...</td>\n",
       "      <td>London (CNN) -- Few shows can claim such an au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         prompt_text  \\\n",
       "0  Nasa has warned of an impending asteroid pass ...   \n",
       "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...   \n",
       "2  By . David Kent . Andy Carroll has taken an un...   \n",
       "3  Los Angeles (CNN) -- Los Angeles has long been...   \n",
       "4  London (CNN) -- Few shows can claim such an au...   \n",
       "\n",
       "                                        prompt_title  \\\n",
       "0  2004 BL86 will pass about three times the dist...   \n",
       "1  Iraqi Islamic Party calls Quran incident \"blat...   \n",
       "2  Carroll takes to Instagram to post selfie ahea...   \n",
       "3  Pop stars from all over Europe are setting the...   \n",
       "4  NEW: Young athletes light the Olympic cauldron...   \n",
       "\n",
       "                                   generated_summary  \n",
       "0  Nasa has warned of an impending asteroid pass ...  \n",
       "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...  \n",
       "2  By . David Kent . Andy Carroll has taken an un...  \n",
       "3  Los Angeles (CNN) -- Los Angeles has long been...  \n",
       "4  London (CNN) -- Few shows can claim such an au...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Store GPT-2 summaries in a DataFrame ---\n",
    "\n",
    "results_df_gpt2 = train_sample.copy()\n",
    "results_df_gpt2[\"generated_summary\"] = generated_summaries_gpt2\n",
    "\n",
    "# Preview\n",
    "results_df_gpt2[[\"prompt_text\", \"prompt_title\", \"generated_summary\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e10fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.16322296501504488\n",
      "ROUGE-2: 0.0707278938022373\n",
      "ROUGE-L: 0.10861939238521591\n"
     ]
    }
   ],
   "source": [
    "rouge_scores_gpt2 = compute_rouge_score(\n",
    "    train_sample[\"prompt_title\"].tolist(),\n",
    "    results_df_gpt2[\"generated_summary\"].tolist()\n",
    ")\n",
    "\n",
    "print(\"ROUGE-1:\", rouge_scores_gpt2[\"rouge1\"])\n",
    "print(\"ROUGE-2:\", rouge_scores_gpt2[\"rouge2\"])\n",
    "print(\"ROUGE-L:\", rouge_scores_gpt2[\"rougeL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247233fe",
   "metadata": {},
   "source": [
    "#### Per-row ROUGE score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6680ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge_per_row(references, predictions):\n",
    "    \"\"\"\n",
    "    Compute ROUGE scores per row and return as a DataFrame.\n",
    "    \"\"\"\n",
    "    per_row_data = []\n",
    "\n",
    "    for ref, pred in zip(references, predictions):\n",
    "        score = compute_rouge_score([ref], [pred])\n",
    "        per_row_data.append({\n",
    "            \"reference\": ref,\n",
    "            \"prediction\": pred,\n",
    "            \"ROUGE-1\": score[\"rouge1\"],\n",
    "            \"ROUGE-2\": score[\"rouge2\"],\n",
    "            \"ROUGE-L\": score[\"rougeL\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(per_row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4fa3b",
   "metadata": {},
   "source": [
    "### Per-row ROUGE for T5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0faedd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "      <td>the asteroid, designated 2004 BL86, will pass ...</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.345679</td>\n",
       "      <td>0.409639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iraqi Islamic Party calls Quran incident \"blat...</td>\n",
       "      <td>a sniper section leader used a Quran for targe...</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carroll takes to Instagram to post selfie ahea...</td>\n",
       "      <td>the striker is out for four months after teari...</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pop stars from all over Europe are setting the...</td>\n",
       "      <td>aspiring pop stars from the u.s. and abroad ar...</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.237624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW: Young athletes light the Olympic cauldron...</td>\n",
       "      <td>a billion people around the world would be glu...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  2004 BL86 will pass about three times the dist...   \n",
       "1  Iraqi Islamic Party calls Quran incident \"blat...   \n",
       "2  Carroll takes to Instagram to post selfie ahea...   \n",
       "3  Pop stars from all over Europe are setting the...   \n",
       "4  NEW: Young athletes light the Olympic cauldron...   \n",
       "\n",
       "                                          prediction   ROUGE-1   ROUGE-2  \\\n",
       "0  the asteroid, designated 2004 BL86, will pass ...  0.481928  0.345679   \n",
       "1  a sniper section leader used a Quran for targe...  0.298851  0.141176   \n",
       "2  the striker is out for four months after teari...  0.256410  0.052632   \n",
       "3  aspiring pop stars from the u.s. and abroad ar...  0.297030  0.141414   \n",
       "4  a billion people around the world would be glu...  0.363636  0.069767   \n",
       "\n",
       "    ROUGE-L  \n",
       "0  0.409639  \n",
       "1  0.206897  \n",
       "2  0.128205  \n",
       "3  0.237624  \n",
       "4  0.295455  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_row_t5_small = compute_rouge_per_row(\n",
    "    train_sample[\"prompt_title\"].tolist(),\n",
    "    results_df[\"generated_summary\"].tolist()\n",
    ")\n",
    "\n",
    "# Per-row ROUGE for T5-base\n",
    "per_row_t5_base = compute_rouge_per_row(\n",
    "    train_sample[\"prompt_title\"].tolist(),\n",
    "    results_df_t5_base[\"generated_summary\"].tolist()\n",
    ")\n",
    "\n",
    "# Per-row ROUGE for GPT-2\n",
    "per_row_gpt2 = compute_rouge_per_row(\n",
    "    train_sample[\"prompt_title\"].tolist(),\n",
    "    results_df_gpt2[\"generated_summary\"].tolist()\n",
    ")\n",
    "\n",
    "# Display first few rows of one model\n",
    "per_row_t5_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba8366",
   "metadata": {},
   "source": [
    "#### ROUGE Score Interpretation for GPT-2\n",
    "\n",
    "- **ROUGE-1 (0.16):** Only about 16% unigram overlap between GPT-2 summaries and the reference summaries, which is very low.\n",
    "- **ROUGE-2 (0.07):** Around 7% bigram overlap, showing that GPT-2 rarely captures correct short phrase structures.\n",
    "- **ROUGE-L (0.10):** Only about 10% overlap in the longest common subsequence, indicating that GPT-2 does not follow the structure of the reference summaries.\n",
    "\n",
    "These results confirm that GPT-2 performs poorly on summarization tasks compared to T5-small and T5-base. GPT-2 is not designed for summarization — it is a general-purpose language model without fine-tuning for this task — which explains the very low ROUGE scores and why its predictions often repeat parts of the input text rather than creating true summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e1f2c",
   "metadata": {},
   "source": [
    "### Part VIII : Comparing All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3899ec52",
   "metadata": {},
   "source": [
    "#### Create comparison table for average ROUGE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32df11c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T5-small</td>\n",
       "      <td>0.365197</td>\n",
       "      <td>0.170770</td>\n",
       "      <td>0.268307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T5-base</td>\n",
       "      <td>0.403797</td>\n",
       "      <td>0.204898</td>\n",
       "      <td>0.297476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-2</td>\n",
       "      <td>0.163223</td>\n",
       "      <td>0.070728</td>\n",
       "      <td>0.108619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model   ROUGE-1   ROUGE-2   ROUGE-L\n",
       "0  T5-small  0.365197  0.170770  0.268307\n",
       "1   T5-base  0.403797  0.204898  0.297476\n",
       "2     GPT-2  0.163223  0.070728  0.108619"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stocker les scores ROUGE globaux dans un dict\n",
    "avg_scores = {\n",
    "    \"Model\": [\"T5-small\", \"T5-base\", \"GPT-2\"],\n",
    "    \"ROUGE-1\": [\n",
    "        rouge_scores[\"rouge1\"],         # T5-small\n",
    "        rouge_scores_t5_base[\"rouge1\"], # T5-base\n",
    "        rouge_scores_gpt2[\"rouge1\"]     # GPT-2\n",
    "    ],\n",
    "    \"ROUGE-2\": [\n",
    "        rouge_scores[\"rouge2\"],\n",
    "        rouge_scores_t5_base[\"rouge2\"],\n",
    "        rouge_scores_gpt2[\"rouge2\"]\n",
    "    ],\n",
    "    \"ROUGE-L\": [\n",
    "        rouge_scores[\"rougeL\"],\n",
    "        rouge_scores_t5_base[\"rougeL\"],\n",
    "        rouge_scores_gpt2[\"rougeL\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Créer DataFrame\n",
    "avg_scores_df = pd.DataFrame(avg_scores)\n",
    "avg_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8899f27",
   "metadata": {},
   "source": [
    "#### Side-by-side comparison of generated summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "922316f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Reference Summary</th>\n",
       "      <th>T5-small Summary</th>\n",
       "      <th>T5-base Summary</th>\n",
       "      <th>GPT-2 Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nasa has warned of an impending asteroid pass ...</td>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "      <td>the asteroid, designated 2004 BL86, will pass ...</td>\n",
       "      <td>2004 BL86 will pass about three times the dist...</td>\n",
       "      <td>Nasa has warned of an impending asteroid pass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...</td>\n",
       "      <td>Iraqi Islamic Party calls Quran incident \"blat...</td>\n",
       "      <td>a sniper section leader used a Quran for targe...</td>\n",
       "      <td>u.s. soldier's desecration of the holy book re...</td>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By . David Kent . Andy Carroll has taken an un...</td>\n",
       "      <td>Carroll takes to Instagram to post selfie ahea...</td>\n",
       "      <td>the striker is out for four months after teari...</td>\n",
       "      <td>england striker posts glum-looking selfie in h...</td>\n",
       "      <td>By . David Kent . Andy Carroll has taken an un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- Los Angeles has long been...</td>\n",
       "      <td>Pop stars from all over Europe are setting the...</td>\n",
       "      <td>aspiring pop stars from the u.s. and abroad ar...</td>\n",
       "      <td>singers from all over Europe and farther east ...</td>\n",
       "      <td>Los Angeles (CNN) -- Los Angeles has long been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London (CNN) -- Few shows can claim such an au...</td>\n",
       "      <td>NEW: Young athletes light the Olympic cauldron...</td>\n",
       "      <td>a billion people around the world would be glu...</td>\n",
       "      <td>\"Isles of Wonder\" features tributes to the Bri...</td>\n",
       "      <td>London (CNN) -- Few shows can claim such an au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Nasa has warned of an impending asteroid pass ...   \n",
       "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...   \n",
       "2  By . David Kent . Andy Carroll has taken an un...   \n",
       "3  Los Angeles (CNN) -- Los Angeles has long been...   \n",
       "4  London (CNN) -- Few shows can claim such an au...   \n",
       "\n",
       "                                   Reference Summary  \\\n",
       "0  2004 BL86 will pass about three times the dist...   \n",
       "1  Iraqi Islamic Party calls Quran incident \"blat...   \n",
       "2  Carroll takes to Instagram to post selfie ahea...   \n",
       "3  Pop stars from all over Europe are setting the...   \n",
       "4  NEW: Young athletes light the Olympic cauldron...   \n",
       "\n",
       "                                    T5-small Summary  \\\n",
       "0  the asteroid, designated 2004 BL86, will pass ...   \n",
       "1  a sniper section leader used a Quran for targe...   \n",
       "2  the striker is out for four months after teari...   \n",
       "3  aspiring pop stars from the u.s. and abroad ar...   \n",
       "4  a billion people around the world would be glu...   \n",
       "\n",
       "                                     T5-base Summary  \\\n",
       "0  2004 BL86 will pass about three times the dist...   \n",
       "1  u.s. soldier's desecration of the holy book re...   \n",
       "2  england striker posts glum-looking selfie in h...   \n",
       "3  singers from all over Europe and farther east ...   \n",
       "4  \"Isles of Wonder\" features tributes to the Bri...   \n",
       "\n",
       "                                       GPT-2 Summary  \n",
       "0  Nasa has warned of an impending asteroid pass ...  \n",
       "1  BAGHDAD, Iraq (CNN) -- Iraq's most powerful Su...  \n",
       "2  By . David Kent . Andy Carroll has taken an un...  \n",
       "3  Los Angeles (CNN) -- Los Angeles has long been...  \n",
       "4  London (CNN) -- Few shows can claim such an au...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construire un DataFrame combiné\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Article\": train_sample[\"prompt_text\"],\n",
    "    \"Reference Summary\": train_sample[\"prompt_title\"],\n",
    "    \"T5-small Summary\": results_df[\"generated_summary\"],\n",
    "    \"T5-base Summary\": results_df_t5_base[\"generated_summary\"],\n",
    "    \"GPT-2 Summary\": results_df_gpt2[\"generated_summary\"]\n",
    "})\n",
    "\n",
    "# Afficher les 5 premiers exemples\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8514fc7",
   "metadata": {},
   "source": [
    "### Final Comparison of Models (T5-small vs T5-base vs GPT-2)\n",
    "\n",
    "#### **1. Average ROUGE Scores**\n",
    "- **T5-small:** ROUGE-1 = 0.36, ROUGE-2 = 0.17, ROUGE-L = 0.26  \n",
    "- **T5-base:** ROUGE-1 = 0.40, ROUGE-2 = 0.20, ROUGE-L = 0.29  \n",
    "- **GPT-2:** ROUGE-1 = 0.16, ROUGE-2 = 0.07, ROUGE-L = 0.10  \n",
    "\n",
    "T5-base clearly outperforms T5-small, achieving higher overlap with the reference summaries. GPT-2 performs significantly worse, as expected, because it is not specialized for summarization tasks.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Qualitative Comparison (Side-by-Side Summaries)**\n",
    "- **T5-small:** Produces reasonable summaries, but sometimes misses key details or uses more generic phrasing.\n",
    "- **T5-base:** More accurate and closer to reference summaries, often capturing both the structure and important details.\n",
    "- **GPT-2:** Largely copies parts of the input text rather than producing a concise summary, reflecting its lack of fine-tuning for summarization.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Key Observations**\n",
    "- Model size and fine-tuning matter: T5-base (larger and trained for summarization) clearly performs best.\n",
    "- ROUGE scores provide a good quantitative comparison, aligning with the qualitative analysis of generated summaries.\n",
    "- GPT-2 is unsuitable for summarization without fine-tuning, as shown by low ROUGE scores and poor output quality.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Conclusion**\n",
    "For summarization tasks, models explicitly trained for summarization (like the T5 family) significantly outperform general-purpose models like GPT-2. Among T5 variants, T5-base offers a noticeable improvement over T5-small, making it a better choice for tasks requiring higher accuracy and better content coverage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
