{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371b44d9",
   "metadata": {},
   "source": [
    "## Daily Challenge: W6_D2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed734df9",
   "metadata": {},
   "source": [
    "### Fine-Tuning GPT-2 for SMS Spam Classification (Legacy transformers API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91651062",
   "metadata": {},
   "source": [
    "In this daily challenge, you will fine-tune a pre-trained GPT-2 model to classify SMS messages as spam or ham (not spam). You will work through loading the dataset, inspecting its schema, tokenizing examples, adapting to an older transformers version, and running training and evaluation with the classic do_train/do_eval flags.\n",
    "\n",
    "What You Will Learn\n",
    "\n",
    "- How to load and explore a custom text-classification dataset\n",
    "- Inspecting and aligning column names for tokenization\n",
    "- Tokenizing text for GPT-2 (with its peculiar padding setup)\n",
    "- Initializing GPT2ForSequenceClassification\n",
    "- Defining and computing multiple evaluation metrics\n",
    "- Configuring TrainingArguments for transformers < 4.4 (using do_train, eval_steps, etc.)\n",
    "- Running fine-tuning with Trainer and interpreting results\n",
    "- Common pitfalls when using legacy APIs\n",
    "\n",
    "What You Will Create\n",
    "\n",
    "By the end of this challenge, you will have built:\n",
    "\n",
    "- A tokenized SMS dataset compatible with GPT-2 requirements, including custom padding and truncation.\n",
    "- A fine-tuned GPT2ForSequenceClassification model that can accurately label incoming SMS messages as spam or ham.\n",
    "- A complete training pipeline using the legacy do_train/do_eval flags in TrainingArguments, with periodic checkpointing, logging, and evaluation.\n",
    "- A set of evaluation metrics (accuracy, precision, recall, F1) computed at each validation step and summarized after training.\n",
    "- A reusable Jupyter notebook that ties everything togetherâ€”from dataset loading and inspection, through model initialization and tokenization, to training, evaluation, and results interpretation.\n",
    "\n",
    "Prerequisites\n",
    "\n",
    "- Python 3.7+\n",
    "- Installed packages: datasets, evaluate, transformers>=4.0.0,<4.4.0\n",
    "- Basic familiarity with Hugging Face datasets and transformers libraries\n",
    "- GitHub or Colab access for executing the notebook\n",
    "- A Hugging Face API and a WeightAndBiases API\n",
    "\n",
    "Task\n",
    "\n",
    "You will fine-tune a GPT-2 model to classify SMS messages as spam or ham using an older version of transformers (<4.4). Follow the steps below and complete the TODO sections.\n",
    "\n",
    "1. Setup\n",
    "\n",
    "Install the required packages datasets, evaluate, and transformers[sentencepiece].\n",
    "\n",
    "2. Load and Inspect Dataset\n",
    "\n",
    "Import the dataset and inspect its structure. You will load the UCI SMS Spam dataset (sms_spam) from the Hugging Face hub and split it into training and validation subsets. You should see the features sms and label.\n",
    "\n",
    "3. Tokenization\n",
    "\n",
    "Import the GPT-2 tokenizer and prepare the tokenization function. GPT-2 does not have a padding token by default, so set it to the end-of-sequence token. Apply tokenization to your dataset with truncation and fixed maximum length.\n",
    "\n",
    "4. Model Initialization\n",
    "\n",
    "Load the GPT-2 model with a sequence classification head. Configure the number of labels (spam vs. ham) and set the padding token ID.\n",
    "\n",
    "5. Metrics Definition\n",
    "\n",
    "Load evaluation metrics (accuracy, precision, recall, F1). Define a function compute_metrics that computes all metrics from model predictions. \n",
    "\n",
    "Reflect on why precision and recall are important in an imbalanced dataset and how you would interpret a model with high accuracy but low recall on the spam class.\n",
    "\n",
    "6. TrainingArguments Configuration\n",
    "\n",
    "Configure TrainingArguments for your experiment: output directories, batch sizes, number of epochs, learning rate, weight decay, evaluation and saving intervals, and logging.\n",
    "\n",
    "Think about the effect of weight decay during fine-tuning and when you might choose a higher or lower value.\n",
    "\n",
    "7. Train and Evaluate\n",
    "\n",
    "Create a Trainer instance with your model, arguments, datasets, and metrics function. Launch training and evaluation. Print and interpret your final results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619619cd",
   "metadata": {},
   "source": [
    "### 1) Setup: Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07cbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install essential libraries for dataset handling and model training\n",
    "%pip install --quiet datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e15d37",
   "metadata": {},
   "source": [
    "### 2. Load & Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486ee8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable symlink warnings from huggingface_hub\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import warnings\n",
    "from transformers import logging\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import Trainer\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f68b3",
   "metadata": {},
   "source": [
    "#### Load and inspect the SMS Spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4124a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sms': Value('string'), 'label': ClassLabel(names=['ham', 'spam'])}\n"
     ]
    }
   ],
   "source": [
    "# Load the UCI SMS Spam dataset from the Hugging Face Hub (with correct namespace)\n",
    "raw_dataset = load_dataset(\"ucirvine/sms_spam\")\n",
    "\n",
    "# Split the dataset: 4,000 samples for training, 1,000 for validation\n",
    "train_dataset = raw_dataset[\"train\"].select(range(4000))\n",
    "val_dataset = raw_dataset[\"train\"].select(range(4000, 5000))\n",
    "\n",
    "# Print the features of the train dataset to inspect column names\n",
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381edbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plain_text']\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "print(get_dataset_config_names(\"ucirvine/sms_spam\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac74181",
   "metadata": {},
   "source": [
    "### 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1931c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model name (GPT-2 base model)\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# GPT-2 has no pad token by default; set pad_token to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define a function to tokenize each example\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sms\"],\n",
    "        padding=\"max_length\",   # pad sequences to max_length\n",
    "        truncation=True,        # truncate longer sequences\n",
    "        max_length=64           # max sequence length (64 tokens)\n",
    "    )\n",
    "\n",
    "# Apply tokenization to the train dataset\n",
    "train_tokenized = train_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "# Apply tokenization to the validation dataset\n",
    "val_tokenized = val_dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb940c",
   "metadata": {},
   "source": [
    "### 4) Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3326a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GPT-2 model with a classification head\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    model_name,         # \"gpt2\"\n",
    "    num_labels=2,       # Two classes: ham and spam\n",
    "    pad_token_id=tokenizer.eos_token_id  # Padding token is set to EOS token ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68813313",
   "metadata": {},
   "source": [
    "### 5) Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3193e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics from the evaluate library\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "# Define a function to compute all metrics at once\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    # Convert logits to predicted class indices\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"precision\": precision_metric.compute(predictions=predictions, references=labels, average=\"binary\")[\"precision\"],\n",
    "        \"recall\": recall_metric.compute(predictions=predictions, references=labels, average=\"binary\")[\"recall\"],\n",
    "        \"f1\": f1_metric.compute(predictions=predictions, references=labels, average=\"binary\")[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1c377",
   "metadata": {},
   "source": [
    "### 6) TrainingArguments Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2c97d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-sms-spam\",     # directory to save checkpoints and model\n",
    "    do_train=True,                    # enable training\n",
    "    do_eval=True,                     # enable evaluation during training\n",
    "    eval_steps=500,                   # evaluate every 500 steps\n",
    "    save_steps=500,                   # save checkpoint every 500 steps\n",
    "    logging_dir=\"./logs\",             # directory for logs\n",
    "    logging_steps=500,                # log metrics every 500 steps\n",
    "\n",
    "    per_device_train_batch_size=8,    # batch size per device during training\n",
    "    per_device_eval_batch_size=8,     # batch size for evaluation\n",
    "    num_train_epochs=3,               # number of epochs\n",
    "    learning_rate=5e-5,               # learning rate\n",
    "    weight_decay=0.01,                # weight decay for regularization\n",
    "\n",
    "    report_to=None,                   # disable integrations like W&B\n",
    "    save_total_limit=1,                # keep only last checkpoint\n",
    "    dataloader_pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe1ebf",
   "metadata": {},
   "source": [
    "### 7) Trainer: Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69dc919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 31:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0471334308385849, 'eval_accuracy': 0.993, 'eval_precision': 0.9852941176470589, 'eval_recall': 0.9640287769784173, 'eval_f1': 0.9745454545454545, 'eval_runtime': 38.3176, 'eval_samples_per_second': 26.098, 'eval_steps_per_second': 3.262, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,                      # your GPT-2 model\n",
    "    args=training_args,               # training configuration\n",
    "    train_dataset=train_tokenized,    # tokenized training dataset\n",
    "    eval_dataset=val_tokenized,       # tokenized validation dataset\n",
    "    compute_metrics=compute_metrics   # function to compute evaluation metrics\n",
    ")\n",
    "\n",
    "# Launch training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "evaluation_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1db95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./my_gpt2_spam_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a87f2",
   "metadata": {},
   "source": [
    "### Interpretation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73d249",
   "metadata": {},
   "source": [
    "The final evaluation metrics obtained on the validation set are:\n",
    "\n",
    "- **Loss:** 0.0471\n",
    "- **Accuracy:** 99.3%\n",
    "- **Precision:** 98.5%\n",
    "- **Recall:** 96.4%\n",
    "- **F1 Score:** 97.5%\n",
    "\n",
    "---\n",
    "\n",
    "**Detailed Interpretation**\n",
    "\n",
    "- **Loss (0.0471):**\n",
    "  This is the cross-entropy loss on the validation data. A very low loss indicates that the model's predicted probabilities are close to the true labels.\n",
    "\n",
    "- **Accuracy (99.3%):**\n",
    "  Almost all SMS messages were classified correctly. However, in imbalanced datasets (where most messages are \"ham\"), accuracy alone can be misleading.\n",
    "\n",
    "- **Precision (98.5%):**\n",
    "  Out of all messages predicted as spam, 98.5% were truly spam. High precision means the model rarely marks legitimate messages (ham) as spam (few false positives).\n",
    "\n",
    "- **Recall (96.4%):**\n",
    "  Out of all real spam messages, the model correctly identified 96.4%. High recall means the model rarely misses spam (few false negatives).\n",
    "\n",
    "- **F1 Score (97.5%):**\n",
    "  The F1 score balances precision and recall. A high F1 indicates the model achieves both high detection of spam and low false alarms.\n",
    "\n",
    "---\n",
    "\n",
    "**Overall Assessment**\n",
    "\n",
    "These metrics show the model has **excellent performance** on the validation set. The classifier is effective at detecting spam while maintaining a very low error rate on ham messages.\n",
    "\n",
    "---\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- The dataset is relatively small (5,000 examples), so results could differ in production.\n",
    "- Because the dataset is imbalanced (more ham than spam), always check precision and recall alongside accuracy.\n",
    "- There may still be edge cases where the model could fail, especially on very short or ambiguous messages.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "To further improve or validate the model:\n",
    "\n",
    "- Evaluate on additional, real-world SMS samples not seen during training.\n",
    "- Perform **cross-validation** or train/test splits with different seeds.\n",
    "- Experiment with:\n",
    "  - Adjusting num_train_epochs (e.g., 2 or 4 epochs)\n",
    "  - Tuning **learning_rate** or **weight_decay**\n",
    "  - Enabling **early stopping** if validation metrics stop improving\n",
    "- Save the trained model and create inference scripts to classify new messages.\n",
    "\n",
    "---\n",
    "\n",
    "Overall, this fine-tuned GPT-2 classifier demonstrates strong capability in spam detection and is ready for further testing and potential deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56690052",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b957af5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get raw predictions (logits) and true labels from the validation set\n",
    "predictions_output = trainer.predict(val_tokenized)\n",
    "\n",
    "# Convert logits to predicted class indices\n",
    "y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
    "\n",
    "# True labels\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"ham\", \"spam\"])\n",
    "disp.plot(cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e32059",
   "metadata": {},
   "source": [
    "### 1. Load and Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ea276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sms': Value('string'), 'label': ClassLabel(names=['ham', 'spam'])}\n"
     ]
    }
   ],
   "source": [
    "# Load and Inspect the SMS Spam Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset(\"ucirvine/sms_spam\")\n",
    "\n",
    "train_dataset = raw_dataset[\"train\"].select(range(4000))\n",
    "val_dataset = raw_dataset[\"train\"].select(range(4000, 5000))\n",
    "\n",
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd603e63",
   "metadata": {},
   "source": [
    "### 2. Tokenization Function for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a703f2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770723db416243679f13c0586232ce96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c165bc7493af452ab21112291ba2082a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aaa378106d34864aee2ebb6c8cc2ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0105047b4b8e4289be6486bb97f39c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee4c9e53e1c41d38fa051d2fce92e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538ffc6a387d4f9c8f4bb9b7c70ea927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b401d1926b4b2488aa5ce68cc1251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import BERT tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Model name\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    bert_model_name,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Tokenization function adapted for BERT\n",
    "def bert_tokenize_fn(examples):\n",
    "    return bert_tokenizer(\n",
    "        examples[\"sms\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64\n",
    "    )\n",
    "\n",
    "# Tokenize datasets\n",
    "bert_train_tokenized = train_dataset.map(bert_tokenize_fn, batched=True)\n",
    "bert_val_tokenized = val_dataset.map(bert_tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775134c2",
   "metadata": {},
   "source": [
    "### 3. Define Training Arguments for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe4c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-sms-spam\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs-bert\",\n",
    "    logging_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=None,\n",
    "    save_total_limit=1,\n",
    "    dataloader_pin_memory=False  # Disable pin_memory to remove warning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471e856",
   "metadata": {},
   "source": [
    "### 4. Create Trainer and Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a246d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 30:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.04754660924275716, metrics={'train_runtime': 1813.065, 'train_samples_per_second': 6.619, 'train_steps_per_second': 0.827, 'total_flos': 394666583040000.0, 'train_loss': 0.04754660924275716, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=bert_training_args,\n",
    "    train_dataset=bert_train_tokenized,\n",
    "    eval_dataset=bert_val_tokenized,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "bert_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016f4c2",
   "metadata": {},
   "source": [
    "### 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b863271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06384330987930298, 'eval_accuracy': 0.992, 'eval_precision': 1.0, 'eval_recall': 0.9424460431654677, 'eval_f1': 0.9703703703703703, 'eval_runtime': 33.022, 'eval_samples_per_second': 30.283, 'eval_steps_per_second': 3.785, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model Performance\n",
    "bert_eval_results = bert_trainer.evaluate()\n",
    "\n",
    "print(bert_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781629a",
   "metadata": {},
   "source": [
    "### 6. Generate Confusion Matrix for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edc315ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGwCAYAAADrIxwOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPvFJREFUeJzt3QmcjWX7wPHrOZYZ22DEIGPLOmUpvIiibCHZ2sUUKaJiCnlf2aOoFFlKvZQsL4p/KbIVyT6VZJcpU2G8iTE0DDP/z3XXOe8cUXOc53HmzPl9fZ7POc967jOfY841133d92NlZGRkCAAAgI1cdl4MAABAEWAAAADbEWAAAADbEWAAAADbEWAAAADbEWAAAADbEWAAAADb5bb/kjlbenq6/Pzzz1KoUCGxLCvQzQEA+Einfzp58qSULl1aXC7n/s5OTU2Vs2fP+n2dvHnzSnh4uAQbAgwfaXARHR0d6GYAAPyUmJgoZcqUcSy4yFeomMi5035fq2TJkpKQkBB0QQYBho80c6HyxsSKlStvoJsDOOLgZy8GugmAY04mJ0ulCtGe3+dOOKuZi3OnJSwmVsSf74rzZ+XwzrfN9Qgwcjh3t4gGFwQYyKkiIiIC3QTAcVekmzt3uF/fFRlW8JZKEmAAAOAUy0Qy/p0fpAgwAABwiuX6ffHn/CAVvC0HAADZFhkMAACcYll+dpEEbx8JAQYAAE6x6CIBAACwDRkMAACcYtFFAgAAbOfys5sjeDsagrflAAAg2yKDAQCAUyy6SAAAgN0sRpEAAADYhgwGAABOsegiAQAAdrNCt4uEAAMAAKdYoZvBCN7QCAAAZFtkMAAAcIpFFwkAAHCki8Tl3/lBKnhDIwAAkG2RwQAAwCku6/fFn/ODFBkMAACcrsGw/Fh8cP78eXn22WelQoUKki9fPrnmmmtk1KhRkpGR4TlGnw8dOlRKlSpljmnevLns27fP6zrHjh2TLl26SEREhBQpUkR69OghKSkpPrWFAAMAgBzihRdekKlTp8prr70mu3btMuvjxo2TSZMmeY7R9YkTJ8q0adNk06ZNUqBAAWnVqpWkpqZ6jtHgYseOHbJixQpZsmSJrF27Vh555BGf2kIXCQAA2XwejOTkZK/NYWFhZrnQ+vXrpX379tK2bVuzXr58eZk7d65s3rzZk7145ZVXZMiQIeY49c4770hUVJQsXrxY7r33XhOYLFu2TLZs2SJ169Y1x2iA0qZNG3nxxReldOnSWWo6GQwAALJ5F0l0dLQULlzYs4wdO/aiL3fjjTfKqlWrZO/evWZ927Ztsm7dOmndurVZT0hIkMOHD5tuETe9Xv369WXDhg1mXR+1W8QdXCg93uVymYxHVpHBAAAgm0tMTDT1EG4Xy16oZ555xmQ7qlWrJrly5TI1Gc8995zp8lAaXCjNWGSm6+59+liiRAmv/blz55bIyEjPMVlBgAEAQDbvIomIiPAKMC5l/vz5Mnv2bJkzZ45ce+218vXXX0u/fv1Mt0ZsbKxcSQQYAADkkJk8BwwYYLIYWkuhatSoIT/88IPpUtEAo2TJkmb7kSNHzCgSN12vXbu2ea7HJCUleV333LlzZmSJ+/ysoAYDAACnMxiWH4sPTp8+bWolMtOukvT0dPNch69qkKB1Gm7apaK1FQ0bNjTr+nj8+HGJj4/3HLN69WpzDa3VyCoyGAAA5BDt2rUzNRdly5Y1XSRfffWVvPzyy9K9e3ez37Is02UyevRoqVy5sgk4dN4M7ULp0KGDOaZ69epy2223Sc+ePc1Q1rS0NOnbt6/JimR1BIkiwAAAIId0kUyaNMkEDI899pjp5tCA4NFHHzUTa7kNHDhQTp06Zea10ExF48aNzbDU8PBwzzFax6FBRbNmzUxGpHPnzmbuDJ+anpF5ei/8LU0l6ZCesBo9xcqVN9DNARzx65bXAt0EwNHf41HFCsuJEyeyVDjp13dF8zFi5f7fF7evMs6lypmV/3S0rU6hBgMAANiOLhIAABzj8q+LJIjzAAQYAABk83kwglHwhkYAACDbIoMBAICjGQyXf+cHKQIMAAByyDDV7CR4Ww4AALItMhgAADjFCt0iTwIMAACcYoVuFwkBBgAATrFCN4MRvKERAADItshgAADgFIsuEgAAYDeLLhIAAADbkMEAAMAhlmWZxY8LSLAiwAAAwCFWCAcYdJEAAADbkcEAAMAp1h+LP+cHKQIMAAAcYtFFAgAAYB8yGAAAOMQK4QwGAQYAAA6xCDAAAIDdrBAOMKjBAAAAtiODAQCAUyyGqQIAAJtZdJEAAADYhwwGAACO3q3d8uMCErQIMAAAcIil//zq5gjeCIMuEgAAYDsyGAAAOMQK4SJPAgwAAJxihe4wVbpIAADIIcqXL+/JmmRe+vTpY/anpqaa58WKFZOCBQtK586d5ciRI17XOHjwoLRt21by588vJUqUkAEDBsi5c+d8bgsZDAAAnGL510WS4eO5W7ZskfPnz3vWv/32W2nRooXcddddZr1///7y0UcfyYIFC6Rw4cLSt29f6dSpk3zxxRdmv56rwUXJkiVl/fr1cujQIenWrZvkyZNHxowZ41NbCDAAAMimNRjWH+cmJyd7bQ8LCzPLhYoXL+61/vzzz8s111wjTZo0kRMnTshbb70lc+bMkVtvvdXsnzFjhlSvXl02btwoDRo0kOXLl8vOnTtl5cqVEhUVJbVr15ZRo0bJoEGDZPjw4ZI3b94st50uEgAAHGJdpLvC10VFR0ebjIN7GTt27N++9tmzZ+Xdd9+V7t27m+vEx8dLWlqaNG/e3HNMtWrVpGzZsrJhwwazro81atQwwYVbq1atTICzY8cOn947GQwAALK5xMREiYiI8KxfLHtxocWLF8vx48flwQcfNOuHDx82GYgiRYp4HafBhO5zH5M5uHDvd+/zBQEGAADZfBRJRESEV4CRFdod0rp1ayldurQEAl0kAABk8y4SX/3www+mjuLhhx/2bNPCTe020axGZjqKRPe5j7lwVIl73X1MVhFgAACQw8yYMcMMMdURIW516tQxo0FWrVrl2bZnzx4zLLVhw4ZmXR+3b98uSUlJnmNWrFhhsicxMTE+tYEuEgAAsvkoEl+kp6ebACM2NlZy5/7f17wWh/bo0UPi4uIkMjLSBA2PP/64CSp0BIlq2bKlCSS6du0q48aNM3UXQ4YMMXNnZKXuIzMCDAAAclCAsXLlSpOV0NEjF5owYYK4XC4zwdaZM2fMCJEpU6Z49ufKlUuWLFkivXv3NoFHgQIFTKAycuRIn9tBgAEAQA7SsmVLycjIuOi+8PBwmTx5slkupVy5cvLxxx/73Q4CDAAAclAGI7sgwAAAwCkWNzsDAACwDRkMAAAcYtFFAgAA7GYRYAAAALtZIRxgUIMBAABsRwYDAACnWKE7ioQAAwAAh1h0kQAAANiHDAauOJfLkmceaSN331ZPShSLkMP/PSFzlmySF99a5nVclfJRMvzxDtLohkqSK5dL9iQcltiBb8qPR341+2M7NpI7W9WVmlXLSETBfFLulgGSnPJbgN4VcHmmz18jk95dJUm/JMt1la+WFwbcJXWuLR/oZsEmFhmM7Kdp06bSr1+/QDcDDujXrYV073yTDBy/QOrfPVqGT/o/eaJrc3nkniaeY8pffZUsnR4n+74/LLc/+qo0vm+sCUBSz6Z5jskXnkdWbdgpE2YuD9A7Afzz/vJ4GfLKIhn0cGv5bNYgE2B0fnyyHD12MtBNg00s/Wf5sQRxEQYZDFxx/6hZUT5e840s/2KHWU88dEw6t6orda4t5znm2cfayYr1O2TYpP/zbPv+p/96XWfa3M/MY6MbKl+xtgN2mjJntXTrcKN0uaOhWX958L3m/8W7H2yQ/g+2DHTzgJyZwUDOtfmbA9KkXlW5pmwJs65/tTWoVVFWrt9p1jVqb9HoWtl/MEkWTuwjez8ZKytmPC1tmtQMcMsB+5xNOydf706Upv+o6tmmt9Fu8o+qsmV7QkDbBvtY/mQv/OxeCbRsHWCkp6fLwIEDJTIyUkqWLCnDhw/37Hv55ZelRo0a5l710dHR8thjj0lKSopn/8yZM6VIkSLmvvZVq1aV/Pnzy5133imnT5+Wt99+W8qXLy9FixaVJ554Qs6fPx+gdxiaJry9Qt5fES+bFwyRpA2vypp3B8m0eZ/JgmVbzf7ikQWlUIFw6RfbwnSBdHr8Nfnos20ya9zDcuMNlQLdfMAWvxxPkfPn06V4ZCGv7cUjI0w9BnLYMFXLjyVIZesuEg0E4uLiZNOmTbJhwwZ58MEHpVGjRtKiRQsT6U+cOFEqVKggBw4cMAGGBiNTpkzxnK/BhB4zb948OXnypHTq1Ek6duxoAg+9172e17lzZ3PNe+6556JtOHPmjFnckpP5j++vjs1vkLtuqyc9h7wtuw8ckhpVrpYxcXfKoaMnZN5Hm8Rl/R73Ll2zXabO/dQ8/3bvT6ZrpXunxrL+y/0BfgcAgKAOMGrWrCnDhg0zzytXriyvvfaarFq1ygQYmQtANRsxevRo6dWrl1eAkZaWJlOnTpVrrrnGrGsGY9asWXLkyBEpWLCgxMTEyC233CKffvrpJQOMsWPHyogRIxx/r6Fk5JMd5JU/shhq53c/S5lSkdL/wRYmwNC/7NLOnZfdCYe8ztubcFga1K4YoFYD9ipWpKAZHXVhQefRY8lmdBVyBotRJNk3wMisVKlSkpSUZJ6vXLlSmjVrJldffbUUKlRIunbtKr/88ovJWrhpt4g7uFBRUVEmGNHgIvM29zUvZvDgwXLixAnPkpiYaPO7DD35wvKa7q/M0tMzPJkLDS6+2vmDVC4X5XWM1mwkHvp9iCoQ7PLmyS21q0XLmi17PNv0/8XaLXulXo0KAW0b7GNRg5E95cmTx2tdf9D6H/D777+X22+/3QQg7733nsTHx8vkyZPNMWfPnv3L8y91zUsJCwuTiIgIrwX+WbZuu8Q91EpaNrpWoktFStumNeWx+28xdRZuE2etlI4tbjAV9hXKXCU977pZbrvpOnlr4VrPMSWKFZLrqlwtFaOvMuvXVipt1otE5A/I+wJ89dj9t8o7i9fL3CUbzTwvcc//R079dka6tGsQ6KbBJpbl/xKssnUXyaVoQKFBwUsvvWRqMdT8+fMD3Sxk0aDxC+SfvW6XFwfdI1cVLWgm2pr5/hcy7s2lnmM++uwbiRs7zwzVe/6pO82Ikm6D3pSN2w54jnmo001mwi63j6f3N4+PjZglc5dsusLvCvBdp5Z15L/HU2TM6x9J0i8nTT2SjpyiiwQ5QVAGGJUqVTL1FZMmTZJ27drJF198IdOmTQt0s5BFKafPyD9ffs8sf2X2hxvNcikvTP/YLEAwe+TuJmZBzvR7FsKfGgwJWtm6i+RSatWqZYapvvDCC3LdddfJ7NmzTTEmAADZiuVn90gQBxhWRkZGRqAbEUx0mGrhwoUlrEZPsXLlDXRzAEf8uuW1QDcBcPT3eFSxwqZw36m6uuQ/visqPrFQcoUVuOzrnD9zSg5MvNPRtjolKLtIAAAIBlYID1MlwAAAwCGWnyNBgji+CM4aDAAAkL2RwQAAwCEul2WWy5Xhx7mBRoABAIBDLLpIAAAA7EMGAwAAh1iMIgEAAHazQriLhAADAACHWCGcwaAGAwCAHOSnn36SBx54QIoVKyb58uWTGjVqyNatWz37dQLvoUOHSqlSpcz+5s2by759+7yucezYMenSpYuZPbRIkSLSo0cPSUlJ8akdBBgAADicwbD8WHzx66+/SqNGjSRPnjyydOlS2blzp7nzeNGiRT3HjBs3TiZOnGhuErpp0yYpUKCAtGrVSlJTUz3HaHCxY8cOWbFihSxZskTWrl0rjzzyiE9toYsEAIBsXoORnJzstT0sLMwsF9KbgEZHR8uMGTM82ypUqOCVvXjllVdkyJAh0r59e7PtnXfekaioKFm8eLHce++9smvXLlm2bJls2bJF6tata47Ru5e3adNGXnzxRSldunSW2k4GAwCAbC46OtrcPM29XOoO4h988IEJCu666y4pUaKEXH/99TJ9+nTP/oSEBDl8+LDpFnHT69WvX182bNhg1vVRu0XcwYXS410ul8l4ZBUZDAAAHGKJn0Wef9yvPTEx0etuqhfLXqgDBw7I1KlTJS4uTv75z3+aLMQTTzwhefPmldjYWBNcKM1YZKbr7n36qMFJZrlz55bIyEjPMVlBgAEAQDbvIomIiMjS7drT09NN5mHMmDFmXTMY3377ram30ADjSqKLBACAHKJUqVISExPjta169epy8OBB87xkyZLm8ciRI17H6Lp7nz4mJSV57T937pwZWeI+JisIMAAAyCGjSBo1aiR79uzx2rZ3714pV66cp+BTg4RVq1Z59msBqdZWNGzY0Kzr4/HjxyU+Pt5zzOrVq012RGs1soouEgAAcshMnv3795cbb7zRdJHcfffdsnnzZnnjjTfM8vv1LOnXr5+MHj1aKleubAKOZ5991owM6dChgyfjcdttt0nPnj1N10paWpr07dvXjDDJ6ggSRYABAEAOUa9ePVm0aJEMHjxYRo4caQIIHZaq81q4DRw4UE6dOmXmtdBMRePGjc2w1PDwcM8xs2fPNkFFs2bNzOiRzp07m7kzfGFl6KBYZJmmknRIT1iNnmLlyhvo5gCO+HXLa4FuAuDo7/GoYoXlxIkTWSqc9Oe74vohSyRXeIHLvs751FPy1ejbHW2rU8hgAADgEIubnQEAALtZ3OwMAADAPmQwAABwiuVnN0fwJjAIMAAAcIpFFwkAAIB9yGAAAOAQi1EkAADAbhZdJAAAAPYhgwEAgEMsukgAAIDdLLpIAAAA7EMGAwAAh1ghnMEgwAAAwCEWNRgAAMBuVghnMKjBAAAAtiODAQCAQyy6SAAAgN0sukgAAADsQwYDAACHWH52cwRv/oIAAwAAx7gsyyz+nB+s6CIBAAC2I4MBAIBDLEaRAAAAu1khPIqEAAMAAIe4rN8Xf84PVtRgAAAA25HBAADAKZaf3RxBnMEgwAAAwCFWCBd50kUCAABsRwYDAACHWH/88+f8YEWAAQCAQ1yMIgEAAMFu+PDhnrk33Eu1atU8+1NTU6VPnz5SrFgxKViwoHTu3FmOHDnidY2DBw9K27ZtJX/+/FKiRAkZMGCAnDt3zue2kMEAACAHTbR17bXXysqVKz3ruXP/76u+f//+8tFHH8mCBQukcOHC0rdvX+nUqZN88cUXZv/58+dNcFGyZElZv369HDp0SLp16yZ58uSRMWPG+NQOAgwAAHLQKJLcuXObAOFCJ06ckLfeekvmzJkjt956q9k2Y8YMqV69umzcuFEaNGggy5cvl507d5oAJSoqSmrXri2jRo2SQYMGmexI3rx5s96OrBz0wQcfZPmCd9xxR5aPBQAAfy85OdlrPSwszCwXs2/fPildurSEh4dLw4YNZezYsVK2bFmJj4+XtLQ0ad68uedY7T7RfRs2bDABhj7WqFHDBBdurVq1kt69e8uOHTvk+uuvF1sDjA4dOmQ5laPpFQAAILbdrj06Otpr+7Bhw0xG4UL169eXmTNnStWqVU33xogRI+Smm26Sb7/9Vg4fPmwyEEWKFPE6R4MJ3af0MXNw4d7v3ueLLAUY6enpPl0UAACIbV0kiYmJEhER4dl+qexF69atPc9r1qxpAo5y5crJ/PnzJV++fBI0o0i0GhUAAFycdcGIjstZlAYXmZdLBRgX0mxFlSpVZP/+/aYu4+zZs3L8+HGvY3QUibtmQx8vHFXiXr9YXYetAYZ2gWjBx9VXX22GuBw4cMBsf/bZZ03xCAAAyB5SUlLku+++k1KlSkmdOnXMaJBVq1Z59u/Zs8cMS9VaDaWP27dvl6SkJM8xK1asMEFNTEyMswHGc889Z/p3xo0b51VNet1118mbb77p6+UAAMjxXSSWH4svnn76aVmzZo18//33Zphpx44dJVeuXHLfffeZYak9evSQuLg4+fTTT03R50MPPWSCCi3wVC1btjSBRNeuXWXbtm3yySefyJAhQ8zcGVnNmlz2MNV33nlH3njjDWnWrJn06tXLs71WrVqye/duXy8HAECO5bKpyDOrfvzxRxNM/PLLL1K8eHFp3LixGYKqz9WECRPE5XKZCbbOnDljRohMmTLFc74GI0uWLDGjRjTwKFCggMTGxsrIkSN9brvPAcZPP/0klSpVumghqA5/AQAAgTFv3ry/3K9DVydPnmyWS9Gi0I8//tjvtvjcRaKpk88///xP2xcuXOjT+FgAAHI6y4YlWPmcwRg6dKhJl2gmQ7MW77//vikS0a4TTasAAIDATRWeXficwWjfvr18+OGHZhpR7ZvRgGPXrl1mW4sWLZxpJQAACCqXdS8SnRVMh60AAIBLc4Xw7dov+2ZnW7duNZkLd12Gjq8FAAD/E8pdJD4HGO4hMHprV/d85jor2I033miqV8uUKeNEOwEAQE6uwXj44YfNcFTNXhw7dsws+lwLPnUfAAD4nys1yVbQZzB0hjCdHUzv1OamzydNmmRqMwAAwO/oIvGB3jL2YhNq6T1K9P7zAADgd6Fc5OlzF8n48ePl8ccfN0Webvr8ySeflBdffNHu9gEAgJyawShatKhXmubUqVPmHvO5c/9++rlz58zz7t27S4cOHZxrLQAAQcSii+SvvfLKK863BACAHMbyc7rv4A0vshhg6NTgAAAAjk+0pVJTU+Xs2bNe2yIiIvy5JAAAOYbrCt+uPaiLPLX+om/fvlKiRAlzLxKtz8i8AAAA/+fACPa5MHwOMAYOHCirV6+WqVOnSlhYmLz55psyYsQIM0RV76gKAADgcxeJ3jVVA4mmTZvKQw89ZCbXqlSpkpQrV05mz54tXbp0caalAAAEGSuER5H4nMHQqcErVqzoqbfQddW4cWNZu3at/S0EACBIWXSRZJ0GFwkJCeZ5tWrVZP78+Z7MhvvmZwAAILT5HGBot8i2bdvM82eeeUYmT54s4eHh0r9/fxkwYIATbQQAIKhHkbj8WEKmBkMDCbfmzZvL7t27JT4+3tRh1KxZ0+72AQAQtCw/uzmCOL7wbx4MpcWdugAAAG9WCBd5ZinAmDhxYpYv+MQTT/jTHgAAkANkKcCYMGFCliOtUAkwvl89nllLkWMd/O/pQDcBcEzKydNXtNDR5ef5OTrAcI8aAQAAWWeFcBdJMAdHAAAgpxZ5AgCAi7MsHarq3/nBigADAACHuPwMMPw5N9DoIgEAALYjgwEAgEMsijx98/nnn8sDDzwgDRs2lJ9++slsmzVrlqxbt87u9gEAEPRdJC4/lpAJMN577z1p1aqV5MuXT7766is5c+aM2X7ixAkZM2aME20EAAA5PcAYPXq0TJs2TaZPny558uTxbG/UqJF8+eWXdrcPAICgZQX4du3PP/+86Wbp16+fZ1tqaqr06dNHihUrJgULFpTOnTvLkSNHvM47ePCgtG3bVvLnzy8lSpQwNzM9d+6cswHGnj175Oabb/7T9sKFC8vx48d9vRwAADmWK4B3U92yZYu8/vrrf7oRqd609MMPP5QFCxbImjVr5Oeff5ZOnTp59p8/f94EF2fPnpX169fL22+/LTNnzpShQ4f69t59bXDJkiVl//79f9qu9RcVK1b09XIAAORYLhuWy5GSkiJdunQxvQ1Fixb1bNdyhrfeektefvllufXWW6VOnToyY8YME0hs3LjRHLN8+XLZuXOnvPvuu1K7dm1p3bq1jBo1SiZPnmyCDl/eu0969uwpTz75pGzatMmkXTTymT17tjz99NPSu3dvXy8HAAD+RnJystfirn+8FO0C0SxE8+bNvbbHx8dLWlqa1/Zq1apJ2bJlZcOGDWZdH2vUqCFRUVGeY7T2Ul93x44d4tgw1WeeeUbS09OlWbNmcvr0adNdEhYWZgKMxx9/3NfLAQCQY1l+1lG4z42OjvbaPmzYMBk+fPhFz5k3b56pidQukgsdPnxY8ubNK0WKFPHarsGE7nMfkzm4cO9373MswNCsxb/+9S9T8KFdJZqGiYmJMYUiAADgf1ziXx2Fnq8SExO97uCtf9hfjB6nvQwrVqyQ8PBwCcqJtjQC0sACAAA4KyIiwivAuBTtAklKSpIbbrjBq2hz7dq18tprr8knn3xi6ih0UEbmLIaOItEaS6WPmzdv9rque5SJ+xhHAoxbbrnlL2cWW716ta+XBAAgR7Js6iLJKi1f2L59u9e2hx56yNRZDBo0yHS16BQTq1atMsNT3aNDdViqTp6p9PG5554zgYoOUVWaEdEAx5fEgs8BhlaUZqbFIl9//bV8++23Ehsb6+vlAADIsVxX+GZnhQoVkuuuu85rW4ECBcycF+7tPXr0kLi4OImMjDRBg9ZPalDRoEEDs79ly5YmkOjatauMGzfO1F0MGTLEFI5eqmvGlgBjwoQJF92uxSZajwEAALIv/R53uVwmg6GjUXSEyJQpUzz7c+XKJUuWLDEjQzXw0ABFEwgjR4706XWsjIyMDDsarAWf//jHP+TYsWOSk+kwHZ1U7NDR41nqDwOC0Y/Hfgt0EwDHpJxMljpVSpk5IZz6PZ78x3fF4EVfSniBQpd9ndRTJ2VsxxscbWu2v5uqjpsNdMUqAAChXIMR1AFG5ulElSZADh06JFu3bpVnn33WzrYBAIBQCTA05ZOZ9uNUrVrV9M1oYQgAAAhMkWfQBhg6llaHu+gUopnnNgcAAH9m/fHPn/ODlU/3ItHKUs1ScNdUAACynsFw+bEEK59vdqbjaA8cOOBMawAAQI7gc4AxevRoc2MzHSOrxZ0X3uENAAD8LpQzGFmuwdAizqeeekratGlj1u+44w6vKcN1NImua50GAAAQ8734V7fXyMr5OT7AGDFihPTq1Us+/fRTZ1sEAACCXpYDDPeEn02aNHGyPQAA5Bguhqnm/FQNAABXmsVMnllTpUqVvw0ycvq9SAAAgM0BhtZhXDiTJwAAuDiXZZnFn/NDIsC49957pUSJEs61BgCAHMQVwjUYWZ4Hg/oLAADg2CgSAACQRZafhZpWCAQY6enpzrYEAIAcxiWWWfw5P2Ru1w4AALLGCuFhqj7fiwQAAODvkMEAAMAhrhAeRUKAAQCAQ1whPA8GXSQAAMB2ZDAAAHCIFcJFngQYAAA4OUzVCs1hqnSRAAAA25HBAADAIRZdJAAAwIluApef5werYG47AADIpshgAADgEMuy/LobeTDfyZwAAwAAh1h+3hA1eMMLAgwAABzjYiZPAAAA+xBgAABwBbpJrMtYfDV16lSpWbOmREREmKVhw4aydOlSz/7U1FTp06ePFCtWTAoWLCidO3eWI0eOeF3j4MGD0rZtW8mfP7+UKFFCBgwYIOfOnfO5LQQYAAA4PA+G5cfiizJlysjzzz8v8fHxsnXrVrn11lulffv2smPHDrO/f//+8uGHH8qCBQtkzZo18vPPP0unTp08558/f94EF2fPnpX169fL22+/LTNnzpShQ4f6/t4zMjIyfD4rhCUnJ0vhwoXl0NHjJjoEcqIfj/0W6CYAjkk5mSx1qpSSEydOOPZ7PPmP74rpa3ZK/oKFLvs6p1NOSs8mMX61NTIyUsaPHy933nmnFC9eXObMmWOeq927d0v16tVlw4YN0qBBA5PtuP32203gERUVZY6ZNm2aDBo0SI4ePSp58+bN8uuSwQAAwOFhqpYfiztgybycOXPmb19bsxHz5s2TU6dOma4SzWqkpaVJ8+bNPcdUq1ZNypYtawIMpY81atTwBBeqVatW5jXdWZCsIsAAAMDhmTxdfiwqOjraZETcy9ixYy/5mtu3bzf1FWFhYdKrVy9ZtGiRxMTEyOHDh00GokiRIl7HazCh+5Q+Zg4u3Pvd+3zBMFUAALK5xMREry4SDR4upWrVqvL111+bbpWFCxdKbGysqbe40ggwAADI5jN5RvwxKiQrNEtRqVIl87xOnTqyZcsWefXVV+Wee+4xxZvHjx/3ymLoKJKSJUua5/q4efNmr+u5R5m4j8kqukgAAMiGQ1Qtm2byTE9PNzUbGmzkyZNHVq1a5dm3Z88eMyxVazSUPmoXS1JSkueYFStWmOBGu1l8QQYDAIAcYvDgwdK6dWtTuHny5EkzYuSzzz6TTz75xNRu9OjRQ+Li4szIEg0aHn/8cRNU6AgS1bJlSxNIdO3aVcaNG2fqLoYMGWLmzvirbpmLIcAAACCH3OwsKSlJunXrJocOHTIBhU66pcFFixYtzP4JEyaIy+UyE2xpVkNHiEyZMsVzfq5cuWTJkiXSu3dvE3gUKFDA1HCMHDnS97YzD4ZvmAcDoYB5MJCTXcl5MGat2+P3PBhdG1d1tK1OIYMBAIBDrBC+XTtFngAAwHZkMAAAcIjl50iQ4M1fEGAAAOAY6zJuWHbh+cGKLhIAAGA7MhgAADjEJZZZ/Dk/WBFgAADgEIsuEgAAAPuQwQAAwCHWH//8OT9YEWAAAOAQiy4SAAAA+5DBAADAIZafo0joIgEAAH9ihXAXCQEGAAAOsUI4wKAGAwAA2I4MBgAADrEYpgoAAOzmsn5f/Dk/WNFFAgAAbEcGAwAAh1h0kQAAALtZjCIBAACwDxkMAAAcYvnZzRHECQwCDAAAnOJiFAkAAIB9yGAgWzp/Pl1emP6xLFi2RZKOnZSSVxWW+9rWl6e6txIrmKueEDLitx+QmQvXyK79P8rRYydlwrPd5NYbr/Psn/ruclm2ZpscPnpc8uTJLTGVrpa+sbdJzWplPcdMn7tKPt+yW/Yc+Fny5M4l6xaODNC7weWyGEUCZC+vzlohM95fJ5OHPiDVKpaSr3cdlL6jZ0uhguHy6D1NA9084G/9lnpWqlYsJR1a1pO40e/8aX+5q4vL4Mc6SJmSkZJ6Nk3eXfS59P7Xm/LhWwMlskhBc0zaufPS4qYaUrN6WVn8yZYAvAv4ywrhUSQEGMiWtnyTIK1vriEtG//+F1/Z0sXkveXx8uXOHwLdNCBLGterZpZLaXPL9V7rT/dsJ4s+2SL7Eg5J/esrm22PdW1pHv9vxVaHWwtnizwvXxDHF9RgIHuqV7OCrN26V/YfTDLr3+79UTZtOyDNG8YEummA7dLSzsl7SzdJoQLhUqVi6UA3Bwj+AGPhwoVSo0YNyZcvnxQrVkyaN28up06dkgcffFA6dOggI0aMkOLFi0tERIT06tVLzp496zl32bJl0rhxYylSpIg59/bbb5fvvvvOs//77783ffXz58+Xm266ybxGvXr1ZO/evbJlyxapW7euFCxYUFq3bi1Hjx69ZBvPnDkjycnJXguc169bC+nY4gZpcPdoibrxSWnabZw8em9Tueu2eoFuGmCbNZt2SoOOQ6Re+3/JrMWfy7TnekrRwgUC3SzYyCWWuCw/liDOYQQswDh06JDcd9990r17d9m1a5d89tln0qlTJ8nIyDD7V61a5dk+d+5cef/9903A4aaBSFxcnGzdutUc63K5pGPHjpKenu71OsOGDZMhQ4bIl19+Kblz55b7779fBg4cKK+++qp8/vnnsn//fhk6dOgl2zl27FgpXLiwZ4mOjnbwpwK3xSu/koXLtsobI2Pl03cGmVqMybNXydyPNgW6aYBt6tWqJPMn95N3XnpMGtWpKgPGviu/HE8JdLPgQBeJ5ccSrHIHMsA4d+6cCSrKlStntmk2wy1v3rzy73//W/Lnzy/XXnutjBw5UgYMGCCjRo0ywUTnzp29rqfHarZj586dct11/6vUfvrpp6VVq1bm+ZNPPmmCGg1IGjVqZLb16NFDZs6cecl2Dh482AQybprBIMhw3rBJi+XJbi2kU8s6Zj2mUmlJPHxMXnl7uRlNAuQE+cPzStnSV5mlZvVy0q7HC7L4k83S455bA900IHgzGLVq1ZJmzZqZoOKuu+6S6dOny6+//uq1X4MLt4YNG0pKSookJiaa9X379plgoWLFiqYLpXz58mb7wYMHvV6nZs2anudRUVF/CmR0W1LS7/38FxMWFmaun3nBlanAd10ww0wul0sy0n/PcAE5UXp6hpxNOxfoZsBOVuimMAIWYOTKlUtWrFghS5culZiYGJk0aZJUrVpVEhISsnR+u3bt5NixYyYw2bRpk1lU5joNlSdPHs9z9/wJF267sFsFgdfqpuvk5RnLZfm6b+Xgz7/Iks+2ydS5n0qbprUC3TQgS07/dkZ2f/ezWdRPR46Z54eSfpXTqWdl4syl8s2uH+TnI7/Kzn0/ytCX50vSL8nS4qb//VGkx7rPOZ+e7rmeXhvBNQ+G5cc/X2i3vtYbFipUSEqUKGHqGffs2eN1TGpqqvTp08fUL2otovYIHDlyxOsY/WO9bdu25g99vY72IGivQ9AMU9Uvd+2q0EXrILSrZNGiRWbftm3b5LfffjPFmWrjxo3mB6HdE7/88ov5gWlwoQWcat26dYF8K7DZ80/dJWNf/0gGjJ8v//01xUy0FduxkQzocVugmwZkyY59P8rDg173rL/4xhLzeEfzOjLk8U6SkHhUPlg5S46fOCVFIvLLtVWiZcb43lKpXEnPOVNmLZcPVsZ71u/p+4p5fPOFR6VezWuu6PtBcFizZo0JHjTI0IDgn//8p7Rs2dKUDxQo8HsBcf/+/eWjjz6SBQsWmNrCvn37mnKFL774wuw/f/68CS5Kliwp69evNyUN3bp1M3+cjxkzJvsHGJpx0FoIfeMaHem6juaoXr26fPPNNyYTofURWqCpI0K0WFN/CFp/UbRoURN5vfHGG1KqVCkTaT3zzDOBeitwgA7XGxPX2SxAMNIAYNvScZfcrzN7/p1RT91jFgQxy8/Jsnw8V0dYZqY1hvodGx8fLzfffLOcOHFC3nrrLZkzZ47ceuvvtT4zZsww3736h3yDBg1k+fLlJiBZuXKlKSOoXbu2qX8cNGiQDB8+3NRIZusuEq1lWLt2rbRp00aqVKliAomXXnrJDBtVWp9RuXJl8wO555575I477jBvzDTa5ZJ58+aZH5gWdGo0Nn78+EC9FQAAHC3BSL5gugSdQiErNKBQkZGR5lG/N9PS0sy0EG7VqlWTsmXLyoYNG8y6PmqtortuUelgCX3dHTt2ZP8MhkZLF0ZaF9JhqZmHpmamPxyNsDJzD3FVWvSZeV01bdr0T9t0zg1dAADIrqIvGL2oWX33H92XovWF/fr1M2UI7tGVhw8fNhkInUMqMw0mdJ/7mMzBhXu/e19WMVU4AADZfK7wxMREr1GMOsLx72gtxrfffhuwGkUCDAAAsvndVCN8nCZBaxaXLFliShHKlCnj2a6Fm1rjePz4ca8sho4i0X3uYzZv3ux1PfcoE/cxQXsvEi1KWbx4caCbAQCALXdTtfxYfKFlABpc6IjM1atXS4UKFbz216lTx4wG0UEWbjoqUwdL6HxTSh+3b9/uNUeUTiuhAY5OK5FVZDAAAMgh+vTpY0aI/N///Z+ZC8NdM6HDUXXaB33UEZo6Q7UWfmrQ8Pjjj5ugQkeQKB3dqYFE165dZdy4ceYaOhBDr52Vrhk3AgwAAHLI7dqnTp3qGdSQmQ5FdQ9omDBhgueWGzoaRUeITJkyxWsiTO1e6d27twk8dP6M2NhYc8sOXxBgAACQQyKMjAtGSl5MeHi4TJ482SyXohNffvzxx+KPbFmDAQAAghsZDAAAsvkokmBEgAEAgEMsP6cK92ua8QCjiwQAANiODAYAADlkFEl2QoABAIBTrNCNMOgiAQAAtiODAQCAQyxGkQAAALtZITyKhAADAACHWKFbgkENBgAAsB8ZDAAAnGKFbgqDAAMAAIdYIVzkSRcJAACwHRkMAAAcYjGKBAAA2M0K3RIMukgAAID9yGAAAOAUK3RTGAQYAAA4xGIUCQAAgH3IYAAA4BCLUSQAAMBuVuiWYBBgAADgGCt0IwxqMAAAgO3IYAAA4BArhEeREGAAAOAUy89CzeCNL+giAQAA9iODAQCAQ6zQrfEkwAAAwDFW6EYYdJEAAADbkcEAAMAhFqNIAACA3awQniqcLhIAAHKQtWvXSrt27aR06dJiWZYsXrzYa39GRoYMHTpUSpUqJfny5ZPmzZvLvn37vI45duyYdOnSRSIiIqRIkSLSo0cPSUlJ8akdBBgAADhc42n5sfjq1KlTUqtWLZk8efJF948bN04mTpwo06ZNk02bNkmBAgWkVatWkpqa6jlGg4sdO3bIihUrZMmSJSZoeeSRR3xqB10kAADkoFEkrVu3NsvFaPbilVdekSFDhkj79u3NtnfeeUeioqJMpuPee++VXbt2ybJly2TLli1St25dc8ykSZOkTZs28uKLL5rMSFaQwQAAwOEiT8uPfyo5OdlrOXPmzGW1JyEhQQ4fPmy6RdwKFy4s9evXlw0bNph1fdRuEXdwofR4l8tlMh5ZRYABAEA2Fx0dbQIB9zJ27NjLuo4GF0ozFpnpunufPpYoUcJrf+7cuSUyMtJzTFbQRQIAgJM9JJZ/56vExERTcOkWFhYm2R0ZDAAAsnmRZ0REhNdyuQFGyZIlzeORI0e8tuu6e58+JiUlee0/d+6cGVniPiYrCDAAAAgRFSpUMEHCqlWrPNu0pkNrKxo2bGjW9fH48eMSHx/vOWb16tWSnp5uajWyii4SAABy0ERbKSkpsn//fq/Czq+//trUUJQtW1b69esno0ePlsqVK5uA49lnnzUjQzp06GCOr169utx2223Ss2dPM5Q1LS1N+vbta0aYZHUEiSLAAAAgB41T3bp1q9xyyy2e9bi4OPMYGxsrM2fOlIEDB5q5MnReC81UNG7c2AxLDQ8P95wze/ZsE1Q0a9bMjB7p3LmzmTvDp5Zn6KBYZJmmkrSC99DR414FN0BO8uOx3wLdBMAxKSeTpU6VUnLixAnHfo8n//FdsfP7o1LIj9c4mZwsMeWLO9pWp5DBAADAIVYI34uEAAMAgJwzkWe2wSgSAABgOzIYAAA4xKKLBAAA2M3KdD+Ryz0/WBFgAADgFCt0izCowQAAALYjgwEAgEOs0E1gEGAAAOAUK4SLPOkiAQAAtiODAQCAQyxGkQAAANtZoVuEQRcJAACwHRkMAAAcYoVuAoMAAwAAp1iMIgEAALAPGQwAABxj+TkSJHhTGAQYAAA4xKKLBAAAwD4EGAAAwHZ0kQAA4BArhLtICDAAAHCIFcJThdNFAgAAbEcGAwAAh1h0kQAAALtZITxVOF0kAADAdmQwAABwihW6KQwCDAAAHGIxigQAAMA+ZDAAAHCIxSgSAABgNyt0SzAIMAAAcIwVuhEGNRgAAOQwkydPlvLly0t4eLjUr19fNm/efMXbQIABAIDDo0gsP/756j//+Y/ExcXJsGHD5Msvv5RatWpJq1atJCkpSa4kAgwAABwu8rT8WHz18ssvS8+ePeWhhx6SmJgYmTZtmuTPn1/+/e9/y5VEDYaPMjIyzOPJk8mBbgrgmJSTvwW6CYBjUlJOev0+d1JycrIt5194nbCwMLNc6OzZsxIfHy+DBw/2bHO5XNK8eXPZsGGDXEkEGD46efL3D2aVimUD3RQAgJ+/zwsXLuzItfPmzSslS5aUyhWi/b5WwYIFJTra+zra/TF8+PA/Hfvf//5Xzp8/L1FRUV7bdX337t1yJRFg+Kh06dKSmJgohQoVEiuYBygHEY3c9T+X/twjIiIC3RzAdnzGryzNXGhwob/PnRIeHi4JCQkmo2BHey/8vrlY9iK7IcDwkaaaypQpE+hmhCT9xcsvX+RkfMavHKcyFxcGGeHh4XIlXXXVVZIrVy45cuSI13Zd14zKlUSRJwAAOUTevHmlTp06smrVKs+29PR0s96wYcMr2hYyGAAA5CBxcXESGxsrdevWlX/84x/yyiuvyKlTp8yokiuJAAPZnvY1akFTMPQ5ApeDzzjsdM8998jRo0dl6NChcvjwYaldu7YsW7bsT4WfTrMyrsQ4HQAAEFKowQAAALYjwAAAALYjwAAAALYjwMAV1bRpU+nXr1+gmwEAcBgBBgAAsB0BBgAAsB0BBq44nVVu4MCBEhkZaaauzXzDHr3NcI0aNaRAgQLm3gyPPfaYpKSkePbPnDlTihQpIkuWLJGqVauaWxDfeeedcvr0aXn77belfPnyUrRoUXniiSfMDX8Apy1cuNB8ZvPlyyfFihUzd63USY0efPBB6dChg4wYMUKKFy9upgDv1auX170pdG6Cxo0bm8+0nnv77bfLd99959n//fffm3tQzJ8/X2666SbzGvXq1ZO9e/fKli1bzERKeiOs1q1bm3kPgOyEAANXnAYCGkBs2rRJxo0bJyNHjpQVK1Z47vUyceJE2bFjhzlu9erVJhjJTIMJPWbevHnmF/Rnn30mHTt2lI8//tgss2bNktdff9384gecdOjQIbnvvvuke/fusmvXLvNZ7NSpk+c24Do9s3v73Llz5f333zcBh5sGIjrr4tatW82x+vnXz7IG4ZnpJFxDhgyRL7/8UnLnzi3333+/+X/x6quvyueffy779+83kyoB2YpOtAVcKU2aNMlo3Lix17Z69eplDBo06KLHL1iwIKNYsWKe9RkzZuhv7oz9+/d7tj366KMZ+fPnzzh58qRnW6tWrcx2wEnx8fHm8/j999//aV9sbGxGZGRkxqlTpzzbpk6dmlGwYMGM8+fPX/R6R48eNdfbvn27WU9ISDDrb775pueYuXPnmm2rVq3ybBs7dmxG1apVbX53gH/IYOCKq1mzptd6qVKlJCkpyTxfuXKlNGvWTK6++mopVKiQdO3aVX755ReTtXDTbpFrrrnGs67T32rXiKaKM29zXxNwSq1atcznVbtI7rrrLpk+fbr8+uuvXvv18+qmN5vSLj+9Lbvat2+fyYBUrFjRdKHo51gdPHjwkv9n3NM962tm3sbnHdkNAQauuDx58nitax+zpoS1v1n7oPWX6XvvvSfx8fEyefJkc0zmfuuLnX+pawJO0ttia/fe0qVLJSYmRiZNmmRqgxISErJ0frt27eTYsWMmMNEuQ10u/LyrzJ9v/WxfbBufd2Q33OwM2YYGFPpL8qWXXjJ90UqL24DsTL/cGzVqZBatgyhXrpwsWrTI7Nu2bZv89ttvpjhTbdy40WTatIBZM3N79uwxwYUWcKp169YF9L0AdiLAQLZRqVIlSUtLM38F6l92X3zxhUybNi3QzQIuSTMOWpzZsmVLKVGihFnX0RzVq1eXb775xmQievToYQo0NUOnxZp9+/Y1AbSOdtKRI2+88YbpJtRukWeeeSbQbwmwDV0kyDa0v1qHqb7wwgty3XXXyezZs2Xs2LGBbhZwSVo3sXbtWmnTpo1UqVLFBBKagdNho0rrMypXriw333yzuYX2HXfc4RmWrUGGjoTSzJ1+3vv37y/jx48P8DsC7MPt2gHAAToPxvHjx2Xx4sWBbgoQEGQwAACA7QgwAACA7egiAQAAtiODAQAAbEeAAQAAbEeAAQAAbEeAAQAAbEeAAQAAbEeAAQTpJE4dOnTwrDdt2lT69et3xdvx2WefmXtx6IRSl6L7fZlsSme6rF27tl/t0mm59XW//vprv64D4PIRYAA2funrl5ouefPmNfdWGTlypJw7d87x137//fdl1KhRtgUFAOAvbnYG2Oi2226TGTNmyJkzZ+Tjjz+WPn36mNtqDx48+E/H6o2wNBCxQ2RkpC3XAQC7kMEAbBQWFiYlS5Y0t+zu3bu3NG/eXD744AOvbo3nnntOSpcuLVWrVjXbExMT5e6775YiRYqYQKF9+/Ymxe92/vx5iYuLM/v17psDBw6UC+fHu7CLRAOcQYMGmduCa5s0m/LWW2+Z695yyy3mGL2bp2YytF0qPT3d3FyuQoUK5vbievO5hQsXer2OBk16Uy/dr9fJ3M6s0nbpNfLnzy8VK1aUZ5991txF90Kvv/66ab8epz+fEydOeO1/8803zV1Lw8PDpVq1ajJlyhSf2wLAOQQYgIP0i1gzFW56a+89e/bIihUrZMmSJeaLtVWrVlKoUCH5/PPPzS3qCxYsaDIh7vP07pwzZ86Uf//737Ju3To5duyYLFq06C9ft1u3bjJ37lyZOHGi7Nq1y3xZ63X1C/u9994zx2g7Dh06JK+++qpZ1+DinXfekWnTpsmOHTvM3T0feOABWbNmjScQ6tSpk7Rr187UNjz88MOXdXtxfa/6fnbu3Glee/r06TJhwgSvY/bv3y/z58+XDz/8UJYtWyZfffWVPPbYY579eqfdoUOHmmBN39+YMWNMoPL222/73B4ADtGpwgH4LzY2NqN9+/bmeXp6esaKFSsywsLCMp5++mnP/qioqIwzZ854zpk1a1ZG1apVzfFuuj9fvnwZn3zyiVkvVapUxrhx4zz709LSMsqUKeN5LdWkSZOMJ5980jzfs2ePpjfM61/Mp59+avb/+uuvnm2pqakZ+fPnz1i/fr3XsT169Mi47777zPPBgwdnxMTEeO0fNGjQn651Id2/aNGiS+4fP358Rp06dTzrw4YNy8iVK1fGjz/+6Nm2dOnSDJfLlXHo0CGzfs0112TMmTPH6zqjRo3KaNiwoXmekJBgXverr7665OsCcBY1GICNNCuhmQLNTGiXw/33329GRbjVqFHDq+5i27Zt5q91/as+s9TUVPnuu+9Mt4BmGerXr+/Zlzt3bqlbt+6fukncNLuQK1cuadKkSZbbrW04ffq0tGjRwmu7ZlGuv/5681wzBZnboRo2bCi++s9//mMyK/r+UlJSTBFsRESE1zFly5aVq6++2ut19OepWRf9Wem5PXr0kJ49e3qO0esULlzY5/YAcAYBBmAjrUuYOnWqCSK0zkKDgcwKFCjgta5fsHXq1DEp/wsVL178srtlfKXtUB999JHXF7vSGg67bNiwQbp06SIjRowwXUMaEMybN890A/naVu1auTDg0cAKQPZAgAHYSAMILajMqhtuuMH8RV+iRIk//RXvVqpUKdm0aZPcfPPNnr/U4+PjzbkXo1kS/Wtfaye0yPRC7gyKFo+6xcTEmEDi4MGDl8x8aEGlu2DVbePGjeKL9evXmwLYf/3rX55tP/zww5+O03b8/PPPJkhzv47L5TKFsVFRUWb7gQMHTLACIHuiyBMIIP2CvOqqq8zIES3yTEhIMPNUPPHEE/Ljjz+aY5588kl5/vnnzWRVu3fvNsWOfzWHRfny5SU2Nla6d+9uznFfU4smlX7B6+gR7c45evSoyQhot8PTTz9tCju1UFK7IL788kuZNGmSp3CyV69esm/fPhkwYIDpqpgzZ44p1vRF5cqVTfCgWQt9De0quVjBqo4M0fegXUj6c9Gfh44k0RE6SjMgWpSq5+/du1e2b99uhge//PLLPrUHgHMIMIAA0iGYa9euNTUHOkJDswRaW6A1GO6MxlNPPSVdu3Y1X7hai6DBQMeOHf/yutpNc+edd5pgRIdwaq3CqVOnzD7tAtEvaB0BotmAvn37mu06UZeOxNAvbm2HjmTRLhMdtqq0jToCRYMWHcKqo0109IYv7rjjDhPE6GvqbJ2a0dDXvJBmgfTn0aZNG2nZsqXUrFnTaxiqjmDRYaoaVGjGRrMuGuy42wog8Cyt9Ax0IwAAQM5CBgMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAANiOAAMAAIjd/h89WvaOV0eIiQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate Confusion Matrix for BERT\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "predictions_output = bert_trainer.predict(bert_val_tokenized)\n",
    "y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
    "y_true = predictions_output.label_ids\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"ham\", \"spam\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73b7fb",
   "metadata": {},
   "source": [
    "### Confusion Matrix Interpretation - BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd53cd",
   "metadata": {},
   "source": [
    "The confusion matrix for the BERT classifier is as follows:\n",
    "\n",
    "|                   | Predicted Ham | Predicted Spam |\n",
    "|-------------------|---------------|----------------|\n",
    "| **Actual Ham**    | 861            | 0              |\n",
    "| **Actual Spam**   | 8              | 131            |\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- **True Negatives (861):**\n",
    "  All ham messages were correctly identified as ham.\n",
    "  There were no false positives (no legitimate messages marked as spam).\n",
    "\n",
    "- **False Positives (0):**\n",
    "  This is excellent. The model made zero mistakes labeling ham as spam, which is reflected in the perfect precision (1.0).\n",
    "\n",
    "- **False Negatives (8):**\n",
    "  The model failed to detect 8 spam messages, classifying them as ham. This explains why recall is slightly lower (94.2%).\n",
    "\n",
    "- **True Positives (131):**\n",
    "  The model correctly identified 131 spam messages.\n",
    "\n",
    "**Summary:**\n",
    "The BERT classifier is highly precise, never raising a false alarm on legitimate messages. However, it is slightly conservative, missing a few spam messages. This trade-off between recall and precision is typical: the model prioritizes avoiding false positives, resulting in a small number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79859bd3",
   "metadata": {},
   "source": [
    "### Comparative Analysis: GPT-2 vs BERT for SMS Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be6d6a",
   "metadata": {},
   "source": [
    "Below is a side-by-side comparison of the two models trained on the same dataset:\n",
    "\n",
    "| Metric       | GPT-2 Model            | BERT Model             |\n",
    "|--------------|-------------------------|------------------------|\n",
    "| **Accuracy** | 99.3%                   | 99.2%                  |\n",
    "| **Precision**| 98.5%                   | **100%**               |\n",
    "| **Recall**   | **96.4%**               | 94.2%                  |\n",
    "| **F1 Score** | **97.5%**               | 97.0%                  |\n",
    "| **Eval Loss**| 0.0471                  | 0.0638                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Accuracy:**\n",
    "  Both models achieve very high accuracy (>99%), correctly classifying almost all messages.\n",
    "\n",
    "- **Precision:**\n",
    "  BERT has perfect precision (1.0), meaning it never misclassified any ham messages as spam.\n",
    "  GPT-2 had slightly lower precision (98.5%), introducing a few false positives.\n",
    "\n",
    "- **Recall:**\n",
    "  GPT-2 has higher recall (96.4%) compared to BERT (94.2%). This means GPT-2 is better at identifying all spam messages, while BERT misses a few.\n",
    "\n",
    "- **F1 Score:**\n",
    "  GPT-2 edges out slightly in the F1 score because it balances precision and recall more evenly.\n",
    "\n",
    "- **Eval Loss:**\n",
    "  GPT-2â€™s lower loss suggests its predictions were closer to true probabilities overall.\n",
    "\n",
    "---\n",
    "\n",
    "### Confusion Matrix Summary:\n",
    "\n",
    "**GPT-2 Confusion Matrix:**\n",
    "- True Positives: 134\n",
    "- False Negatives: 5\n",
    "- False Positives: 2\n",
    "- True Negatives: 859\n",
    "\n",
    "**BERT Confusion Matrix:**\n",
    "- True Positives: 131\n",
    "- False Negatives: 8\n",
    "- False Positives: 0\n",
    "- True Negatives: 861\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- **GPT-2** is slightly better at detecting more spam messages (higher recall) but introduces a few false positives.\n",
    "- **BERT** is extremely conservative, with perfect precision (never marking ham as spam) but at the cost of slightly lower recall.\n",
    "- Depending on the priority (avoiding false alarms vs. detecting all spam), either model is an excellent choice.\n",
    "\n",
    "For applications where false positives are critical (e.g., not blocking legitimate messages), **BERT** may be preferable.\n",
    "If maximizing spam detection is the top priority, **GPT-2** could be a better fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
