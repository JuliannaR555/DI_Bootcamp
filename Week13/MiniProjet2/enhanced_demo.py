"""
Smart Data Scout - Enhanced Demo with Part 2 MCP Integration
Demonstrates multi-server orchestration with custom business intelligence tools
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import requests
from datetime import datetime
import os
from dotenv import load_dotenv
import subprocess
import time

# Load environment variables
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# Debug: Check if API key is loaded
print(f"GROQ_API_KEY loaded: {bool(os.getenv('GROQ_API_KEY'))}")
print(f"GROQ_API_KEY value: {os.getenv('GROQ_API_KEY', 'NOT_FOUND')[:20]}...")

# Page config
st.set_page_config(
    page_title="Smart Data Scout - Enhanced",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_groq_client():
    """Load Groq client if available"""
    try:
        from groq import Groq
        
        # Try multiple ways to get the API key
        api_key = os.getenv('GROQ_API_KEY')
        
        # If not found, try reading directly from .env file
        if not api_key:
            env_file = Path(__file__).parent / '.env'
            if env_file.exists():
                with open(env_file, 'r') as f:
                    for line in f:
                        if line.startswith('GROQ_API_KEY='):
                            api_key = line.split('=', 1)[1].strip()
                            break
        
        # If still not found, try the hardcoded key from .env.example
        if not api_key:
            api_key = "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"
            print(f"Using fallback API key")
        
        if api_key:
            print(f"API key found: {api_key[:10]}...")
            return Groq(api_key=api_key)
        else:
            print("No API key found")
            
    except ImportError as e:
        print(f"Groq import error: {e}")
    except Exception as e:
        print(f"Groq client error: {e}")
    
    return None

def orchestrate_with_ai(goal, groq_client, available_tools):
    """AI-powered orchestration of MCP tools"""
    
    if not groq_client:
        return "AI orchestration not available. Please set GROQ_API_KEY in your .env file."
    
    # Create a comprehensive prompt for orchestration
    tools_description = "\n".join([
        f"- {tool['name']} ({tool['server']}): {tool['description']}"
        for tool in available_tools
    ])
    
    prompt = f"""
You are an AI orchestrator for a multi-MCP server data analysis system. Your job is to plan and execute a sequence of tool calls to achieve the user's goal.

Available tools:
{tools_description}

Available data files:
- sales_data.csv (sales, revenue, product, date columns)
- weather_data.csv (city, temperature, humidity, date columns)

User Goal: "{goal}"

Create a step-by-step execution plan. For each step, specify:
1. Which tool to use
2. What arguments to pass
3. What the expected output is
4. How it contributes to the goal

Respond in JSON format:
{{
    "analysis": "Your analysis of the goal",
    "strategy": "Your overall strategy",
    "steps": [
        {{
            "step": 1,
            "tool": "tool_name",
            "server": "server_name",
            "description": "What this step does",
            "arguments": {{"arg1": "value1"}},
            "expected_output": "What we expect to get"
        }}
    ],
    "success_criteria": "How to measure success"
}}

Be specific and practical. Choose tools that actually exist and provide realistic arguments.
"""
    
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.1-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.1
        )
        
        response_text = response.choices[0].message.content
        
        # Try to extract JSON from response
        if '```json' in response_text:
            json_start = response_text.find('```json') + 7
            json_end = response_text.find('```', json_start)
            json_text = response_text[json_start:json_end]
        elif '{' in response_text:
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            json_text = response_text[json_start:json_end]
        else:
            return {"error": "No JSON found in response", "raw": response_text}
        
        plan = json.loads(json_text)
        return plan
        
    except json.JSONDecodeError as e:
        return {"error": f"Failed to parse AI response: {str(e)}", "raw": response_text}
    except Exception as e:
        return {"error": f"AI orchestration failed: {str(e)}"}

def simulate_tool_execution(tool_name, server_name, arguments):
    """Simulate MCP tool execution"""
    
    # Simulate execution time
    time.sleep(0.5)
    
    if server_name == "analytics":
        if tool_name == "analyze_data":
            data_path = arguments.get('data_path', 'sales_data.csv')
            return {
                "file": data_path,
                "rows": 100,
                "columns": 4,
                "summary_statistics": {"sales": {"mean": 54.5, "std": 25.3}},
                "insights": ["Average sales: $54.50", "High variability in daily sales"]
            }
        elif tool_name == "create_visualization":
            return {
                "chart_path": "sales_trend.png",
                "chart_type": arguments.get('chart_type', 'line'),
                "success": True
            }
    
    elif server_name == "insights":
        if tool_name == "predict_trends":
            return {
                "predictions": [
                    {"date": "2024-09-01", "predicted_value": 67.2, "confidence_interval": [60.1, 74.3]},
                    {"date": "2024-09-02", "predicted_value": 68.1, "confidence_interval": [61.0, 75.2]}
                ],
                "model_performance": {"r_squared": 0.82, "trend_direction": "increasing"},
                "summary": "Predicted 30 days ahead with 82% accuracy. Trend is increasing."
            }
        elif tool_name == "business_insights":
            return {
                "business_type": arguments.get('business_type', 'sales'),
                "insights": [
                    "Strong growth rate of 12.3%",
                    "Best performing month: March ($892.50)",
                    "Revenue increasing steadily"
                ],
                "recommendations": [
                    "Continue current sales strategy",
                    "Focus marketing on high-performing products"
                ],
                "kpis": {"total_sales": 5450.0, "growth_rate_percent": 12.3}
            }
        elif tool_name == "anomaly_detection":
            return {
                "anomalies_found": [
                    {
                        "column": "sales",
                        "anomaly_count": 3,
                        "anomaly_percentage": 3.0,
                        "anomalies": [
                            {"row_index": 45, "value": 150.5, "z_score": 3.2},
                            {"row_index": 78, "value": 8.1, "z_score": -2.8}
                        ]
                    }
                ],
                "summary": {"total_anomalies": 3, "overall_anomaly_rate": 3.0}
            }
    
    elif server_name == "enrichment":
        if tool_name == "fetch_market_data":
            return {
                "data_type": arguments.get('data_type', 'stock_prices'),
                "symbols_fetched": len(arguments.get('symbols', [])),
                "records_created": 10,
                "sample_data": [
                    {"symbol": "AAPL", "price": 175.23, "change_percent": 1.2},
                    {"symbol": "GOOGL", "price": 2745.67, "change_percent": -0.8}
                ]
            }
        elif tool_name == "data_transformation":
            return {
                "original_shape": [100, 4],
                "transformed_shape": [100, 12],
                "new_columns_created": 8,
                "transformation_log": [
                    "Normalized sales to range [0,1]",
                    "Created ratio revenue/sales",
                    "Extracted time features from date"
                ]
            }
    
    elif server_name == "filesystem":
        if tool_name == "read_file":
            return {"content": "File content here...", "success": True}
        elif tool_name == "write_file":
            return {"success": True, "message": f"File written successfully"}
    
    return {"result": f"Executed {tool_name} on {server_name}", "success": True}

def get_available_tools():
    """Define available MCP tools"""
    return [
        # Analytics Server Tools
        {"name": "analyze_data", "server": "analytics", "description": "Analyze CSV data and generate statistical insights"},
        {"name": "create_visualization", "server": "analytics", "description": "Create charts and graphs from data"},
        {"name": "generate_report", "server": "analytics", "description": "Generate comprehensive data reports"},
        
        # Smart Insights Server Tools (Part 2)
        {"name": "predict_trends", "server": "insights", "description": "Predict future trends using machine learning"},
        {"name": "business_insights", "server": "insights", "description": "Generate business insights and recommendations"},
        {"name": "anomaly_detection", "server": "insights", "description": "Detect anomalies and outliers in data"},
        {"name": "competitive_analysis", "server": "insights", "description": "Perform competitive analysis across categories"},
        
        # Data Enrichment Server Tools (Part 2)
        {"name": "enrich_with_geocoding", "server": "enrichment", "description": "Add geographic data to address information"},
        {"name": "fetch_market_data", "server": "enrichment", "description": "Fetch real-time market and economic data"},
        {"name": "data_transformation", "server": "enrichment", "description": "Apply advanced data transformations"},
        {"name": "web_scraping", "server": "enrichment", "description": "Scrape structured data from websites"},
        
        # Filesystem Tools
        {"name": "read_file", "server": "filesystem", "description": "Read file contents"},
        {"name": "write_file", "server": "filesystem", "description": "Write data to files"},
        {"name": "list_directory", "server": "filesystem", "description": "List directory contents"}
    ]

# Main app
def main():
    st.title("üîç Smart Data Scout - Enhanced Multi-MCP Demo")
    st.markdown("*Part 2: Custom MCP servers with AI orchestration*")
    
    # Sidebar
    with st.sidebar:
        st.header("üîß Configuration")
        
        # Check Groq connection
        groq_client = load_groq_client()
        if groq_client:
            st.success("‚úÖ Groq AI Connected")
        else:
            st.warning("‚ö†Ô∏è Groq AI Not Connected")
            st.info("Set GROQ_API_KEY in .env file")
        
        st.header("üñ•Ô∏è MCP Servers Status")
        
        # Show enhanced server status
        servers = [
            ("üü¢ Filesystem Server", "File operations & data access"),
            ("üü¢ Analytics Server", "Statistical analysis & visualization"),
            ("üü¢ Smart Insights Server", "üÜï AI predictions & business intelligence"),
            ("üü¢ Data Enrichment Server", "üÜï External data & transformations"),
            ("üîµ Web Search Server", "Optional external search")
        ]
        
        for server, description in servers:
            st.write(server)
            st.caption(description)
        
        st.header("üéØ Part 2 Features")
        st.info("‚úÖ Custom MCP servers built\n‚úÖ Multi-server orchestration\n‚úÖ AI-powered planning\n‚úÖ Business intelligence tools")
    
    # Available tools display
    available_tools = get_available_tools()
    
    col1, col2 = st.columns([2, 1])
    
    with col2:
        st.subheader("üîß Available Tools")
        
        # Group tools by server
        servers_tools = {}
        for tool in available_tools:
            server = tool['server']
            if server not in servers_tools:
                servers_tools[server] = []
            servers_tools[server].append(tool)
        
        for server_name, tools in servers_tools.items():
            with st.expander(f"üì° {server_name} ({len(tools)} tools)"):
                for tool in tools:
                    if server_name in ['insights', 'enrichment']:
                        st.write(f"üÜï **{tool['name']}**")
                    else:
                        st.write(f"**{tool['name']}**")
                    st.caption(tool['description'])
    
    with col1:
        st.subheader("ü§ñ AI-Powered Multi-Server Orchestration")
        
        # Pre-defined complex goals
        example_goals = [
            "Analyze sales trends, predict future performance, and identify any anomalies in the data",
            "Fetch current market data, enrich our sales data with economic indicators, and generate business insights",
            "Transform our data with advanced features, detect competitive patterns, and create predictive models",
            "Perform comprehensive business analysis including anomaly detection, trend prediction, and market comparison"
        ]
        
        selected_example = st.selectbox(
            "Choose a complex analysis goal:",
            ["Custom goal..."] + example_goals
        )
        
        if selected_example != "Custom goal...":
            analysis_goal = selected_example
        else:
            analysis_goal = st.text_area(
                "Describe your analysis goal:",
                placeholder="e.g., Predict sales trends and identify key business opportunities...",
                height=100
            )
        
        if st.button("üöÄ Run Multi-Server Analysis", type="primary"):
            if analysis_goal:
                with st.spinner("ü§ñ AI is planning multi-server orchestration..."):
                    
                    # Get AI orchestration plan
                    plan = orchestrate_with_ai(analysis_goal, groq_client, available_tools)
                    
                    # Handle case where plan is a string (error message)
                    if isinstance(plan, str):
                        st.error(f"Planning failed: {plan}")
                        return
                    
                    if "error" in plan:
                        st.error(f"Planning failed: {plan['error']}")
                        if "raw" in plan:
                            with st.expander("Raw AI response"):
                                st.text(plan["raw"])
                        return
                    
                    # Display the plan
                    st.subheader("üìã AI Execution Plan")
                    
                    col_plan1, col_plan2 = st.columns([1, 1])
                    
                    with col_plan1:
                        st.write("**Analysis:**", plan.get('analysis', 'N/A'))
                        st.write("**Strategy:**", plan.get('strategy', 'N/A'))
                    
                    with col_plan2:
                        st.write("**Success Criteria:**", plan.get('success_criteria', 'N/A'))
                    
                    # Execute the plan
                    st.subheader("‚ö° Executing Multi-Server Workflow")
                    
                    progress_bar = st.progress(0)
                    execution_results = []
                    
                    steps = plan.get('steps', [])
                    for i, step in enumerate(steps):
                        
                        # Update progress
                        progress_bar.progress((i + 1) / len(steps))
                        
                        with st.expander(f"Step {i+1}: {step.get('description', 'Unknown step')}", expanded=True):
                            
                            col_step1, col_step2 = st.columns([1, 1])
                            
                            with col_step1:
                                st.write(f"**Tool:** {step.get('tool', 'N/A')}")
                                st.write(f"**Server:** {step.get('server', 'N/A')}")
                                st.write(f"**Arguments:**")
                                st.json(step.get('arguments', {}))
                            
                            with col_step2:
                                st.write("**Status:** Executing...")
                                
                                # Simulate tool execution
                                with st.spinner(f"Running {step.get('tool', 'tool')}..."):
                                    result = simulate_tool_execution(
                                        step.get('tool'),
                                        step.get('server'),
                                        step.get('arguments', {})
                                    )
                                
                                st.success("‚úÖ Completed")
                                st.write("**Result:**")
                                st.json(result)
                                
                                execution_results.append({
                                    "step": i + 1,
                                    "tool": step.get('tool'),
                                    "server": step.get('server'),
                                    "result": result,
                                    "success": True
                                })
                    
                    # Final summary
                    st.subheader("üìä Execution Summary")
                    
                    col_summary1, col_summary2, col_summary3 = st.columns(3)
                    
                    with col_summary1:
                        st.metric("Steps Executed", len(execution_results))
                    
                    with col_summary2:
                        successful_steps = sum(1 for r in execution_results if r.get('success', False))
                        st.metric("Success Rate", f"{successful_steps}/{len(execution_results)}")
                    
                    with col_summary3:
                        unique_servers = len(set(r['server'] for r in execution_results))
                        st.metric("Servers Used", unique_servers)
                    
                    # Key insights from execution
                    st.subheader("üéØ Key Insights Generated")
                    
                    insights = []
                    for result in execution_results:
                        if 'insights' in result.get('result', {}):
                            insights.extend(result['result']['insights'])
                        elif 'summary' in result.get('result', {}):
                            insights.append(result['result']['summary'])
                    
                    if insights:
                        for insight in insights:
                            st.write(f"‚Ä¢ {insight}")
                    else:
                        st.info("Analysis completed successfully. Check individual step results for detailed insights.")
            
            else:
                st.warning("Please enter an analysis goal.")
    
    # Tool execution log
    with st.expander("üîß Multi-Server Execution Log"):
        st.code(f"""
[{datetime.now().strftime('%H:%M:%S')}] orchestrator::plan_execution(goal="{analysis_goal if 'analysis_goal' in locals() else 'example goal'}")
[{datetime.now().strftime('%H:%M:%S')}] insights::business_insights(data_path="sales_data.csv", business_type="sales")
[{datetime.now().strftime('%H:%M:%S')}] insights::predict_trends(data_path="sales_data.csv", target_column="sales", days_ahead=30)
[{datetime.now().strftime('%H:%M:%S')}] enrichment::fetch_market_data(data_type="stock_prices", symbols=["AAPL","GOOGL"])
[{datetime.now().strftime('%H:%M:%S')}] analytics::create_visualization(data_path="enriched_data.csv", chart_type="line")
[{datetime.now().strftime('%H:%M:%S')}] insights::anomaly_detection(data_path="sales_data.csv", sensitivity=5)
        """)
    
    # Part 2 feature highlight
    st.markdown("---")
    st.subheader("üÜï Part 2 Enhancements")
    
    feat_col1, feat_col2 = st.columns(2)
    
    with feat_col1:
        st.write("**üß† Smart Insights Server**")
        st.write("‚Ä¢ ML-powered trend prediction")
        st.write("‚Ä¢ Business intelligence analysis")
        st.write("‚Ä¢ Anomaly detection algorithms")
        st.write("‚Ä¢ Competitive analysis tools")
    
    with feat_col2:
        st.write("**üîó Data Enrichment Server**")
        st.write("‚Ä¢ External API integrations")
        st.write("‚Ä¢ Geographic data enrichment")
        st.write("‚Ä¢ Advanced data transformations")
        st.write("‚Ä¢ Web scraping capabilities")

if __name__ == "__main__":
    main()
