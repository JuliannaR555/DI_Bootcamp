{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebbd412",
   "metadata": {},
   "source": [
    "# Exercises XP Ninja: W4_D3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a7e71",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "- **CNN fundamentals:** architecture, convolution/pooling, and where CNNs fit in ML workflows.\n",
    "- **Neural data preprocessing:** label encoding, feature scaling, train/validation/test splits.\n",
    "- **Modeling with Keras:** building models using the high-level API.\n",
    "- **Sequential API:** creating networks with `keras.Sequential()` (stacking layers).\n",
    "- **Compile & train:** choosing loss/optimizer/metrics and running training loops with callbacks.\n",
    "- **Evaluate models:** interpreting loss/accuracy and basic classification metrics.\n",
    "\n",
    "## What You Will Create\n",
    "- A **CNN model** in Keras to classify records from the provided dataset.\n",
    "- A **preprocessing pipeline** tailored for neural networks (encoding + scaling).\n",
    "- A **trained and evaluated** model with clear metrics (loss, accuracy; optionally precision/recall/F1).\n",
    "- A concise, **reproducible** notebook documenting the end-to-end workflow.\n",
    "\n",
    "## Dataset\n",
    "Use the file: **`hr_comma_sep.xls`** (tabular HR attrition dataset).  \n",
    "Typical columns include continuous features (e.g., satisfaction, evaluation, hours) and categorical features (e.g., department, salary), plus a binary target.\n",
    "\n",
    "## Reading Material (for context)\n",
    "- CNN overview (concepts): https://www.geeksforgeeks.org/deep-learning/convolutional-neural-network-cnn-in-machine-learning/  \n",
    "- Keras tutorial (API usage): https://medium.com/analytics-vidhya/deep-learning-tutorial-with-keras-7a34a1a322cd\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise 1 — Create a Simple Convolutional Neural Network (CNN)\n",
    "\n",
    "**Instructions**\n",
    "1. **Import** required libraries (NumPy, Pandas, scikit-learn) and **Keras** (`tensorflow.keras`).  \n",
    "2. **Load** the dataset `hr_comma_sep.xls` (read as Excel; if needed, fallback to CSV).  \n",
    "3. **Encode** labels and **preprocess** features:  \n",
    "   - Impute missing values if any.  \n",
    "   - One-Hot Encode categorical features.  \n",
    "   - Standardize numeric features.  \n",
    "4. **Split** the data into train/test (and optional validation split during training).  \n",
    "5. **Build** a neural network using `keras.Sequential()` (you may use a 1D CNN or an MLP baseline):  \n",
    "   - Example for CNN-1D on tabular data: `Conv1D` → `BatchNormalization` → `GlobalAveragePooling1D` → `Dense` head.  \n",
    "6. **Compile** the model (e.g., `binary_crossentropy` + `Adam`) and **train** with early stopping (monitor validation loss).  \n",
    "7. **Evaluate** the model on the test set: **loss** and **accuracy** (optionally print precision/recall/F1 and the confusion matrix).\n",
    "\n",
    "**Deliverables**\n",
    "- Clean, runnable notebook with:\n",
    "  - Data loading + preprocessing cells.  \n",
    "  - Model definition, compilation, and training logs.  \n",
    "  - Final **test loss/accuracy** (and optionally precision/recall/F1 + confusion matrix).  \n",
    "  - A short **written interpretation** of results and training dynamics (learning curves if plotted).\n",
    "\n",
    "**Reproducibility & Good Practices**\n",
    "- Fix a random seed (e.g., `RANDOM_STATE = 42`, `tf.random.set_seed(42)`).  \n",
    "- Prevent data leakage: **fit preprocessing on the training data only**, then transform validation/test.  \n",
    "- Keep preprocessing inside reusable functions/pipelines when possible.  \n",
    "- Clearly document chosen hyperparameters (layers, units, activations, learning rate, batch size).\n",
    "\n",
    "**Optional Enhancements**\n",
    "- Plot training/validation **accuracy & loss** curves.  \n",
    "- Perform a **threshold sweep** on predicted probabilities to trade precision vs. recall.  \n",
    "- Try a small **hyperparameter search** (layer sizes, dropout, learning rate).  \n",
    "- Compare CNN-1D vs. a simple **MLP** baseline on the same preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf285c49",
   "metadata": {},
   "source": [
    "## Imports and Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5146e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports and reproducibility ---\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, GlobalAveragePooling1D, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Fix seeds for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "# References (reading material, not used programmatically):\n",
    "# 1) CNN overview: https://www.geeksforgeeks.org/deep-learning/convolutional-neural-network-cnn-in-machine-learning/\n",
    "# 2) Keras tutorial: https://medium.com/analytics-vidhya/deep-learning-tutorial-with-keras-7a34a1a322cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e5706",
   "metadata": {},
   "source": [
    "## Load Dataset (robust to .xls/.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3249cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14999, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load dataset (robust to .xls or .csv) ---\n",
    "DATA_PATH = \"hr_comma_sep.xls\"  # change if needed\n",
    "\n",
    "def load_hr_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Try reading as Excel; if that fails, try CSV.\n",
    "    The classic HR dataset usually has columns like:\n",
    "    ['satisfaction_level','last_evaluation','number_project','average_montly_hours',\n",
    "     'time_spend_company','Work_accident','promotion_last_5years','sales','salary','left']\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(path)\n",
    "    except Exception:\n",
    "        # Fallback: try CSV (some distributions of the dataset are CSV)\n",
    "        df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "df_raw = load_hr_dataset(DATA_PATH)\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94907590",
   "metadata": {},
   "source": [
    "## Preprocess (label encode + feature scale/OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eebe7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature matrix shape: (14999, 20)\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocessing: encode label and scale features ---\n",
    "# Infer target column (typically 'left'); fallback to last column if not found.\n",
    "target_col = None\n",
    "for c in df_raw.columns:\n",
    "    if c.strip().lower() == \"left\":\n",
    "        target_col = c\n",
    "        break\n",
    "if target_col is None:\n",
    "    target_col = df_raw.columns[-1]\n",
    "    print(f\"[Info] Could not find 'left'. Using last column as target: {target_col}\")\n",
    "\n",
    "y = df_raw[target_col].astype(int).values\n",
    "X = df_raw.drop(columns=[target_col]).copy()\n",
    "\n",
    "# Identify categorical vs numeric columns (robust detection)\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Classic HR dataset often has:\n",
    "# cat_cols ~ ['sales','salary']\n",
    "# num_cols ~ the rest\n",
    "\n",
    "def make_ohe():\n",
    "    \"\"\"Return a OneHotEncoder compatible across sklearn versions.\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", make_ohe()),\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Fit-transform features -> dense numpy array\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "if hasattr(X_processed, \"toarray\"):  # safety if sparse\n",
    "    X_processed = X_processed.toarray()\n",
    "\n",
    "print(\"Processed feature matrix shape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba804dfd",
   "metadata": {},
   "source": [
    "## Train/Test Split + Reshape for Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d107670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11999, 20, 1), (3000, 20, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Train/test split + reshape for Conv1D (sequence length = n_features, channels = 1) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Reshape to (samples, timesteps=features, channels=1)\n",
    "def to_cnn1d(x: np.ndarray) -> np.ndarray:\n",
    "    return x.reshape((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "X_train_cnn = to_cnn1d(X_train)\n",
    "X_test_cnn  = to_cnn1d(X_test)\n",
    "\n",
    "X_train_cnn.shape, X_test_cnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfde352",
   "metadata": {},
   "source": [
    "## Build CNN (Keras .Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163c3d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,945</span> (42.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,945\u001b[0m (42.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,753</span> (42.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,753\u001b[0m (42.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Build a simple 1D CNN for tabular data ---\n",
    "# Rationale:\n",
    "# - Treat the feature vector as a 1D \"spatial\" sequence.\n",
    "# - Two small Conv1D blocks + GlobalAveragePooling1D to reduce parameters.\n",
    "# - Dense head for binary classification (sigmoid).\n",
    "\n",
    "n_features = X_train_cnn.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(n_features, 1)),\n",
    "    Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14b9b4",
   "metadata": {},
   "source": [
    "## Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbadc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8647 - loss: 0.4024 - val_accuracy: 0.7667 - val_loss: 0.6326\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.1879 - val_accuracy: 0.7667 - val_loss: 0.6836\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9576 - loss: 0.1614 - val_accuracy: 0.8254 - val_loss: 0.3004\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9583 - loss: 0.1483 - val_accuracy: 0.9717 - val_loss: 0.1297\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9615 - loss: 0.1352 - val_accuracy: 0.9746 - val_loss: 0.1099\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9627 - loss: 0.1296 - val_accuracy: 0.9712 - val_loss: 0.1014\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9634 - loss: 0.1231 - val_accuracy: 0.9688 - val_loss: 0.1082\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9652 - loss: 0.1210 - val_accuracy: 0.9733 - val_loss: 0.1009\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9672 - loss: 0.1155 - val_accuracy: 0.9746 - val_loss: 0.0927\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.1125 - val_accuracy: 0.9737 - val_loss: 0.1001\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9680 - loss: 0.1075 - val_accuracy: 0.9750 - val_loss: 0.0894\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9696 - loss: 0.1037 - val_accuracy: 0.9762 - val_loss: 0.0894\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.1047 - val_accuracy: 0.9758 - val_loss: 0.0880\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9714 - loss: 0.1009 - val_accuracy: 0.9750 - val_loss: 0.0997\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9716 - loss: 0.1022 - val_accuracy: 0.9742 - val_loss: 0.0913\n",
      "Epoch 16/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9687 - loss: 0.0988 - val_accuracy: 0.9746 - val_loss: 0.0909\n",
      "Epoch 17/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9702 - loss: 0.0949 - val_accuracy: 0.9754 - val_loss: 0.0935\n",
      "Epoch 18/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9719 - loss: 0.0961 - val_accuracy: 0.9771 - val_loss: 0.0830\n",
      "Epoch 19/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9710 - loss: 0.0933 - val_accuracy: 0.9779 - val_loss: 0.0863\n",
      "Epoch 20/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 0.0933 - val_accuracy: 0.9783 - val_loss: 0.0807\n",
      "Epoch 21/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9735 - loss: 0.0926 - val_accuracy: 0.9767 - val_loss: 0.0951\n",
      "Epoch 22/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9712 - loss: 0.0930 - val_accuracy: 0.9779 - val_loss: 0.0828\n",
      "Epoch 23/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.0941 - val_accuracy: 0.9762 - val_loss: 0.0810\n",
      "Epoch 24/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9724 - loss: 0.0926 - val_accuracy: 0.9750 - val_loss: 0.0923\n",
      "Epoch 25/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.0876 - val_accuracy: 0.9750 - val_loss: 0.0825\n",
      "Epoch 26/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0875 - val_accuracy: 0.9771 - val_loss: 0.0954\n",
      "Epoch 27/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9738 - loss: 0.0846 - val_accuracy: 0.9771 - val_loss: 0.0773\n",
      "Epoch 28/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0814 - val_accuracy: 0.9771 - val_loss: 0.0877\n",
      "Epoch 29/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.0864 - val_accuracy: 0.9787 - val_loss: 0.0766\n",
      "Epoch 30/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0843 - val_accuracy: 0.9779 - val_loss: 0.0792\n",
      "Epoch 31/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.0789 - val_accuracy: 0.9721 - val_loss: 0.0995\n",
      "Epoch 32/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.0829 - val_accuracy: 0.9779 - val_loss: 0.0724\n",
      "Epoch 33/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9762 - loss: 0.0786 - val_accuracy: 0.9742 - val_loss: 0.0939\n",
      "Epoch 34/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9724 - loss: 0.0827 - val_accuracy: 0.9746 - val_loss: 0.0816\n",
      "Epoch 35/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.0797 - val_accuracy: 0.9787 - val_loss: 0.0711\n",
      "Epoch 36/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0748 - val_accuracy: 0.9742 - val_loss: 0.0866\n",
      "Epoch 37/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.0776 - val_accuracy: 0.9775 - val_loss: 0.0735\n",
      "Epoch 38/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0729 - val_accuracy: 0.9712 - val_loss: 0.0972\n",
      "Epoch 39/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0769 - val_accuracy: 0.9775 - val_loss: 0.0728\n",
      "Epoch 40/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.0742 - val_accuracy: 0.9762 - val_loss: 0.0838\n",
      "Epoch 41/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0726 - val_accuracy: 0.9712 - val_loss: 0.0924\n",
      "Epoch 42/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.0705 - val_accuracy: 0.9767 - val_loss: 0.0720\n",
      "Epoch 43/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9769 - loss: 0.0692 - val_accuracy: 0.9742 - val_loss: 0.0737\n",
      "Epoch 44/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.0694 - val_accuracy: 0.9771 - val_loss: 0.0697\n",
      "Epoch 45/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0681 - val_accuracy: 0.9767 - val_loss: 0.0685\n",
      "Epoch 46/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0676 - val_accuracy: 0.9742 - val_loss: 0.0849\n",
      "Epoch 47/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9798 - loss: 0.0682 - val_accuracy: 0.9767 - val_loss: 0.0784\n",
      "Epoch 48/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9783 - loss: 0.0644 - val_accuracy: 0.9767 - val_loss: 0.0716\n",
      "Epoch 49/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.0651 - val_accuracy: 0.9750 - val_loss: 0.0783\n",
      "Epoch 50/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0686 - val_accuracy: 0.9767 - val_loss: 0.0725\n",
      "Epoch 51/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0672 - val_accuracy: 0.9754 - val_loss: 0.0730\n",
      "Epoch 52/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.0642 - val_accuracy: 0.9779 - val_loss: 0.0699\n",
      "Epoch 53/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0664 - val_accuracy: 0.9742 - val_loss: 0.0767\n",
      "Epoch 54/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9804 - loss: 0.0610 - val_accuracy: 0.9783 - val_loss: 0.0700\n",
      "Epoch 55/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0619 - val_accuracy: 0.9758 - val_loss: 0.0765\n"
     ]
    }
   ],
   "source": [
    "# --- Compile and train the model ---\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b52987",
   "metadata": {},
   "source": [
    "## Evaluate Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16ce1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0822 | Test Accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate model's loss and accuracy ---\n",
    "test_loss, test_acc = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562abb4c",
   "metadata": {},
   "source": [
    "## Extra Diagnostics (not required but useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab4b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.993     0.985      2286\n",
      "           1      0.978     0.927     0.952       714\n",
      "\n",
      "    accuracy                          0.978      3000\n",
      "   macro avg      0.978     0.960     0.969      3000\n",
      "weighted avg      0.978     0.978     0.977      3000\n",
      "\n",
      "Confusion matrix:\n",
      " [[2271   15]\n",
      " [  52  662]]\n"
     ]
    }
   ],
   "source": [
    "# --- Optional: simple diagnostics (precision/recall/F1) ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_prob = model.predict(X_test_cnn, verbose=0).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f706611",
   "metadata": {},
   "source": [
    "## Exercise 1 — CNN on HR Dataset: Results & Interpretation\n",
    "\n",
    "**Test metrics**  \n",
    "- **Accuracy:** 0.978  \n",
    "- **Loss:** 0.082  \n",
    "- **Per-class (from the report):**  \n",
    "  - Class 0 (stay): precision 0.978, recall 0.993, F1 0.985, support 2286  \n",
    "  - Class 1 (left): precision 0.978, recall 0.927, F1 0.952, support 714  \n",
    "- **Confusion matrix:** TN=2271, FP=15, FN=52, TP=662 (N=3000)\n",
    "\n",
    "**What this means**  \n",
    "- The model achieves **very high accuracy** with **balanced precision/recall** across classes despite class imbalance (~24% “left”).  \n",
    "- For the positive class (left), **precision ≈ 0.978** (few false alarms: FP=15) and **recall ≈ 0.927** (most leavers correctly identified: TP=662, FN=52).  \n",
    "- Macro averages (precision/recall/F1 ≈ 0.978/0.960/0.969) indicate strong performance that is not dominated by the majority class.\n",
    "\n",
    "**Training dynamics**  \n",
    "- Validation accuracy climbed from ~0.77 to ~0.98 while validation loss decreased to ~0.07–0.09, suggesting stable optimization.  \n",
    "- Early stopping with weight restoration helped prevent overfitting; training/validation curves are consistent with good generalization on this split.\n",
    "\n",
    "**Caveat (important)**  \n",
    "- Ensure the preprocessing (imputation, scaling, one-hot encoding) is **fit on the training data only**, then applied to the test set.  \n",
    "  Fitting on the full dataset before the split can leak information and **inflate** test scores.\n",
    "\n",
    "**Next steps**  \n",
    "- Re-run with leakage-safe preprocessing and confirm metrics.  \n",
    "- Add repeated/nested CV for stability.  \n",
    "- Consider threshold tuning on `predict_proba` if you need to push recall for Class 1 even higher (accepting more FP).  \n",
    "- Try a simpler MLP baseline for comparison; if performance holds, the CNN-1D approach is a solid choice on this tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3edbb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test shapes: (11999, 20, 1) (3000, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Leakage-safe split, fit preprocessor on train only, then reshape for Conv1D ---\n",
    "\n",
    "# 1) Split raw X, y first (before fitting the preprocessor)\n",
    "X_raw = df_raw.drop(columns=[target_col]).copy()\n",
    "y_raw = df_raw[target_col].astype(int).values\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=RANDOM_STATE, stratify=y_raw\n",
    ")\n",
    "\n",
    "# 2) Fit the preprocessor ONLY on training data\n",
    "preprocessor_leak_safe = preprocessor.fit(X_train_raw)\n",
    "\n",
    "# 3) Transform train and test\n",
    "X_train_proc = preprocessor_leak_safe.transform(X_train_raw)\n",
    "X_test_proc  = preprocessor_leak_safe.transform(X_test_raw)\n",
    "if hasattr(X_train_proc, \"toarray\"):\n",
    "    X_train_proc = X_train_proc.toarray()\n",
    "    X_test_proc  = X_test_proc.toarray()\n",
    "\n",
    "# 4) Reshape for 1D-CNN: (samples, timesteps=features, channels=1)\n",
    "def to_cnn1d(x):\n",
    "    return x.reshape((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "X_train_cnn = to_cnn1d(X_train_proc)\n",
    "X_test_cnn  = to_cnn1d(X_test_proc)\n",
    "\n",
    "print(\"Train/Test shapes:\", X_train_cnn.shape, X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2216408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.4099 - val_accuracy: 0.7671 - val_loss: 0.4893\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1848 - val_accuracy: 0.9171 - val_loss: 0.4557\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.1574 - val_accuracy: 0.9233 - val_loss: 0.2812\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.1409 - val_accuracy: 0.9663 - val_loss: 0.1299\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.1322 - val_accuracy: 0.9688 - val_loss: 0.1122\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9618 - loss: 0.1301 - val_accuracy: 0.9708 - val_loss: 0.1086\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9637 - loss: 0.1204 - val_accuracy: 0.9725 - val_loss: 0.1038\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9637 - loss: 0.1199 - val_accuracy: 0.9725 - val_loss: 0.1019\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.1193 - val_accuracy: 0.9742 - val_loss: 0.0968\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.1104 - val_accuracy: 0.9712 - val_loss: 0.1009\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1125 - val_accuracy: 0.9750 - val_loss: 0.0972\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9687 - loss: 0.1076 - val_accuracy: 0.9479 - val_loss: 0.1502\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1075 - val_accuracy: 0.9704 - val_loss: 0.1049\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.1047 - val_accuracy: 0.9708 - val_loss: 0.1017\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9684 - loss: 0.1035 - val_accuracy: 0.9717 - val_loss: 0.0973\n",
      "Epoch 16/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9689 - loss: 0.1047 - val_accuracy: 0.9737 - val_loss: 0.0941\n",
      "Epoch 17/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9706 - loss: 0.0980 - val_accuracy: 0.9737 - val_loss: 0.0926\n",
      "Epoch 18/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9714 - loss: 0.0960 - val_accuracy: 0.9725 - val_loss: 0.0895\n",
      "Epoch 19/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.0972 - val_accuracy: 0.9754 - val_loss: 0.0854\n",
      "Epoch 20/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9701 - loss: 0.0934 - val_accuracy: 0.9696 - val_loss: 0.1055\n",
      "Epoch 21/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9722 - loss: 0.0927 - val_accuracy: 0.9746 - val_loss: 0.0852\n",
      "Epoch 22/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9693 - loss: 0.0938 - val_accuracy: 0.9721 - val_loss: 0.1020\n",
      "Epoch 23/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.0919 - val_accuracy: 0.9746 - val_loss: 0.0844\n",
      "Epoch 24/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.0902 - val_accuracy: 0.9671 - val_loss: 0.1036\n",
      "Epoch 25/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.0894 - val_accuracy: 0.9762 - val_loss: 0.0796\n",
      "Epoch 26/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9735 - loss: 0.0873 - val_accuracy: 0.9754 - val_loss: 0.0841\n",
      "Epoch 27/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.0850 - val_accuracy: 0.9742 - val_loss: 0.0885\n",
      "Epoch 28/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.0889 - val_accuracy: 0.9742 - val_loss: 0.0903\n",
      "Epoch 29/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0814 - val_accuracy: 0.9737 - val_loss: 0.0877\n",
      "Epoch 30/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.0851 - val_accuracy: 0.9783 - val_loss: 0.0790\n",
      "Epoch 31/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.0816 - val_accuracy: 0.9767 - val_loss: 0.0815\n",
      "Epoch 32/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0835 - val_accuracy: 0.9737 - val_loss: 0.0845\n",
      "Epoch 33/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0788 - val_accuracy: 0.9717 - val_loss: 0.0889\n",
      "Epoch 34/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.0791 - val_accuracy: 0.9775 - val_loss: 0.0816\n",
      "Epoch 35/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0799 - val_accuracy: 0.9767 - val_loss: 0.0786\n",
      "Epoch 36/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.0811 - val_accuracy: 0.9783 - val_loss: 0.0753\n",
      "Epoch 37/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.0731 - val_accuracy: 0.9762 - val_loss: 0.0737\n",
      "Epoch 38/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9765 - loss: 0.0724 - val_accuracy: 0.9733 - val_loss: 0.0850\n",
      "Epoch 39/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0746 - val_accuracy: 0.9758 - val_loss: 0.0733\n",
      "Epoch 40/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9776 - loss: 0.0714 - val_accuracy: 0.9746 - val_loss: 0.0891\n",
      "Epoch 41/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9746 - loss: 0.0752 - val_accuracy: 0.9650 - val_loss: 0.1012\n",
      "Epoch 42/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0754 - val_accuracy: 0.9742 - val_loss: 0.0817\n",
      "Epoch 43/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0731 - val_accuracy: 0.9729 - val_loss: 0.0887\n",
      "Epoch 44/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0714 - val_accuracy: 0.9771 - val_loss: 0.0741\n",
      "Epoch 45/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9774 - loss: 0.0713 - val_accuracy: 0.9779 - val_loss: 0.0768\n",
      "Epoch 46/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0710 - val_accuracy: 0.9742 - val_loss: 0.0814\n",
      "Epoch 47/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0686 - val_accuracy: 0.9762 - val_loss: 0.0723\n",
      "Epoch 48/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0696 - val_accuracy: 0.9725 - val_loss: 0.0801\n",
      "Epoch 49/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0680 - val_accuracy: 0.9712 - val_loss: 0.0892\n",
      "Epoch 50/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0713 - val_accuracy: 0.9758 - val_loss: 0.0753\n",
      "Epoch 51/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0618 - val_accuracy: 0.9737 - val_loss: 0.0770\n",
      "Epoch 52/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0638 - val_accuracy: 0.9767 - val_loss: 0.0723\n",
      "Epoch 53/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0648 - val_accuracy: 0.9754 - val_loss: 0.0788\n",
      "Epoch 54/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0629 - val_accuracy: 0.9779 - val_loss: 0.0733\n",
      "Epoch 55/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0652 - val_accuracy: 0.9746 - val_loss: 0.0798\n",
      "Epoch 56/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0596 - val_accuracy: 0.9792 - val_loss: 0.0695\n",
      "Epoch 57/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0641 - val_accuracy: 0.9792 - val_loss: 0.0685\n",
      "Epoch 58/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0619 - val_accuracy: 0.9750 - val_loss: 0.0716\n",
      "Epoch 59/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.0590 - val_accuracy: 0.9762 - val_loss: 0.0811\n",
      "Epoch 60/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.0628 - val_accuracy: 0.9725 - val_loss: 0.0804\n",
      "Epoch 61/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.0557 - val_accuracy: 0.9746 - val_loss: 0.0755\n",
      "Epoch 62/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0579 - val_accuracy: 0.9787 - val_loss: 0.0741\n",
      "Epoch 63/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9808 - loss: 0.0586 - val_accuracy: 0.9783 - val_loss: 0.0678\n",
      "Epoch 64/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9808 - loss: 0.0586 - val_accuracy: 0.9775 - val_loss: 0.0702\n",
      "Epoch 65/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0563 - val_accuracy: 0.9787 - val_loss: 0.0642\n",
      "Epoch 66/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0552 - val_accuracy: 0.9771 - val_loss: 0.0734\n",
      "Epoch 67/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0540 - val_accuracy: 0.9746 - val_loss: 0.0717\n",
      "Epoch 68/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9798 - loss: 0.0576 - val_accuracy: 0.9771 - val_loss: 0.0700\n",
      "Epoch 69/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9778 - loss: 0.0631 - val_accuracy: 0.9733 - val_loss: 0.0799\n",
      "Epoch 70/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0546 - val_accuracy: 0.9754 - val_loss: 0.0726\n",
      "Epoch 71/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.0591 - val_accuracy: 0.9792 - val_loss: 0.0620\n",
      "Epoch 72/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0517 - val_accuracy: 0.9787 - val_loss: 0.0646\n",
      "Epoch 73/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0496 - val_accuracy: 0.9767 - val_loss: 0.0775\n",
      "Epoch 74/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0503 - val_accuracy: 0.9796 - val_loss: 0.0655\n",
      "Epoch 75/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0511 - val_accuracy: 0.9762 - val_loss: 0.0839\n",
      "Epoch 76/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0501 - val_accuracy: 0.9792 - val_loss: 0.0628\n",
      "Epoch 77/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9834 - loss: 0.0492 - val_accuracy: 0.9746 - val_loss: 0.0725\n",
      "Epoch 78/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0449 - val_accuracy: 0.9792 - val_loss: 0.0680\n",
      "Epoch 79/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0511 - val_accuracy: 0.9750 - val_loss: 0.0681\n",
      "Epoch 80/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0495 - val_accuracy: 0.9796 - val_loss: 0.0699\n",
      "Epoch 81/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0528 - val_accuracy: 0.9762 - val_loss: 0.0748\n"
     ]
    }
   ],
   "source": [
    "# --- Retrain (leakage-safe) and capture history ---\n",
    "# Assumes: df_raw, target_col, preprocessor (built earlier), RANDOM_STATE defined.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 1) Split raw first (no leakage)\n",
    "X_raw = df_raw.drop(columns=[target_col]).copy()\n",
    "y_raw = df_raw[target_col].astype(int).values\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=RANDOM_STATE, stratify=y_raw\n",
    ")\n",
    "\n",
    "# 2) Fit preprocessor on TRAIN only, then transform both\n",
    "preprocessor_leak_safe = preprocessor.fit(X_train_raw)\n",
    "X_train_proc = preprocessor_leak_safe.transform(X_train_raw)\n",
    "X_test_proc  = preprocessor_leak_safe.transform(X_test_raw)\n",
    "if hasattr(X_train_proc, \"toarray\"):  # in case it's sparse\n",
    "    X_train_proc = X_train_proc.toarray()\n",
    "    X_test_proc  = X_test_proc.toarray()\n",
    "\n",
    "# 3) Reshape to (samples, timesteps=features, channels=1)\n",
    "def to_cnn1d(x: np.ndarray) -> np.ndarray:\n",
    "    return x.reshape((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "X_train_cnn = to_cnn1d(X_train_proc)\n",
    "X_test_cnn  = to_cnn1d(X_test_proc)\n",
    "\n",
    "# 4) Define and compile the model\n",
    "n_features = X_train_cnn.shape[1]\n",
    "model = Sequential([\n",
    "    Input(shape=(n_features, 1)),\n",
    "    Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# 5) Train and capture history\n",
    "history = model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffe7f1",
   "metadata": {},
   "source": [
    "### Plot learning curves (accuracy & loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2fdc955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Plot learning curves (accuracy & loss) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    \"\"\"Plot training/validation accuracy and loss from a Keras History object.\"\"\"\n",
    "    hist = history.history\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(hist[\"accuracy\"], label=\"train accuracy\")\n",
    "    plt.plot(hist[\"val_accuracy\"], label=\"val accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Learning Curve — Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Loss\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(hist[\"loss\"], label=\"train loss\")\n",
    "    plt.plot(hist[\"val_loss\"], label=\"val loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Learning Curve — Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ec29a",
   "metadata": {},
   "source": [
    "### Evaluate and auto-generate Markdown summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682fd6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.991     0.986      2286\n",
      "           1      0.970     0.940     0.954       714\n",
      "\n",
      "    accuracy                          0.979      3000\n",
      "   macro avg      0.976     0.965     0.970      3000\n",
      "weighted avg      0.979     0.979     0.979      3000\n",
      "\n",
      "Confusion matrix: [[2265 21] [43 671]]\n",
      "Test Loss: 0.0767 | Test Accuracy: 0.9787 (Keras evaluate)\n",
      "(Threshold=0.50) Acc 0.979 | Prec 0.970 | Rec 0.940 | F1 0.954\n",
      "\n",
      "--- Markdown to copy ---\n",
      "\n",
      "# CNN (1D) — HR Attrition: Results & Interpretation\n",
      "\n",
      "**Test metrics**\n",
      "- **Accuracy:** 0.979\n",
      "- **Loss:** 0.0767\n",
      "- **Precision / Recall / F1:** 0.970 / 0.940 / 0.954\n",
      "- **Confusion matrix:** TN=2265, FP=21, FN=43, TP=671\n",
      "\n",
      "**Per-class (from the classification report)**\n",
      "```\n",
      "precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.991     0.986      2286\n",
      "           1      0.970     0.940     0.954       714\n",
      "\n",
      "    accuracy                          0.979      3000\n",
      "   macro avg      0.976     0.965     0.970      3000\n",
      "weighted avg      0.979     0.979     0.979      3000\n",
      "```\n",
      "\n",
      "**Notes**\n",
      "- Preprocessing was fit on the **training set only** and applied to the test set (leakage-safe).\n",
      "- Threshold used for the positive class = **0.50**. Consider tuning it with `predict_proba` if recall/precision trade-offs are required.\n",
      "\n",
      "**Takeaway**\n",
      "- The model achieves high accuracy with balanced precision/recall on this split.\n",
      "- Learning curves indicate stable optimization and good generalization under early stopping.\n"
     ]
    }
   ],
   "source": [
    "# --- FIX: Evaluate and auto-generate Markdown summary without triple-quoted f-strings ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_and_markdown(model, X_test_cnn, y_test, model_name=\"CNN (1D) — HR Attrition\", threshold=0.50):\n",
    "    \"\"\"Evaluate model, print report/confusion matrix, and return a Markdown summary string.\"\"\"\n",
    "    # Keras evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "\n",
    "    # Predict and threshold\n",
    "    y_prob = model.predict(X_test_cnn, verbose=0).ravel()\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred)\n",
    "    f1   = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    # Per-class report\n",
    "    cls_report = classification_report(y_test, y_pred, digits=3)\n",
    "\n",
    "    # Print for notebook visibility\n",
    "    print(cls_report)\n",
    "    print(f\"Confusion matrix: [[{tn} {fp}] [{fn} {tp}]]\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f} (Keras evaluate)\")\n",
    "    print(f\"(Threshold={threshold:.2f}) Acc {acc:.3f} | Prec {prec:.3f} | Rec {rec:.3f} | F1 {f1:.3f}\")\n",
    "\n",
    "    # Build Markdown safely via join (no triple quotes)\n",
    "    lines = [\n",
    "        f\"# {model_name}: Results & Interpretation\",\n",
    "        \"\",\n",
    "        \"**Test metrics**\",\n",
    "        f\"- **Accuracy:** {acc:.3f}\",\n",
    "        f\"- **Loss:** {test_loss:.4f}\",\n",
    "        f\"- **Precision / Recall / F1:** {prec:.3f} / {rec:.3f} / {f1:.3f}\",\n",
    "        f\"- **Confusion matrix:** TN={tn}, FP={fp}, FN={fn}, TP={tp}\",\n",
    "        \"\",\n",
    "        \"**Per-class (from the classification report)**\",\n",
    "        \"```\",\n",
    "        cls_report.strip(),\n",
    "        \"```\",\n",
    "        \"\",\n",
    "        \"**Notes**\",\n",
    "        \"- Preprocessing was fit on the **training set only** and applied to the test set (leakage-safe).\",\n",
    "        f\"- Threshold used for the positive class = **{threshold:.2f}**. Consider tuning it with `predict_proba` if recall/precision trade-offs are required.\",\n",
    "        \"\",\n",
    "        \"**Takeaway**\",\n",
    "        \"- The model achieves high accuracy with balanced precision/recall on this split.\",\n",
    "        \"- Learning curves indicate stable optimization and good generalization under early stopping.\",\n",
    "    ]\n",
    "    md = \"\\n\".join(lines)\n",
    "    return md\n",
    "\n",
    "# Example usage:\n",
    "md_summary = evaluate_and_markdown(model, X_test_cnn, y_test, model_name=\"CNN (1D) — HR Attrition\", threshold=0.50)\n",
    "print(\"\\n--- Markdown to copy ---\\n\")\n",
    "print(md_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc717856",
   "metadata": {},
   "source": [
    "**Notes**  \n",
    "- Preprocessing was fit on the **training set only** and applied to the test set (leakage-safe).  \n",
    "- Threshold used for positive class = **{threshold:.2f}**. Consider tuning it with `predict_proba` if recall/precision trade-offs are required.\n",
    "\n",
    "**Takeaway**  \n",
    "- The model achieves high accuracy with balanced precision/recall on this split.  \n",
    "- Learning curves indicate stable optimization and good generalization under early stopping.\n",
    "\"\"\"\n",
    "    return md\n",
    "\n",
    "md_summary = evaluate_and_markdown(model, X_test_cnn, y_test, model_name=\"CNN (1D) — HR Attrition\", threshold=0.50)\n",
    "print(\"\\n--- Markdown to copy ---\\n\")\n",
    "print(md_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46a3506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: quick threshold sweep to inspect precision/recall/F1 trade-offs ---\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def threshold_sweep(model, X, y, thresholds=np.linspace(0.2, 0.8, 13)):\n",
    "    \"\"\"Return a DataFrame of metrics across probability thresholds for the positive class.\"\"\"\n",
    "    if not hasattr(model, \"predict_proba\"):\n",
    "        # Keras model doesn't expose predict_proba; use predict (sigmoid output)\n",
    "        proba = model.predict(X, verbose=0).ravel()\n",
    "    else:\n",
    "        proba = model.predict_proba(X)[:, 1]\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yp = (proba >= t).astype(int)\n",
    "        prec = precision_score(y, yp, zero_division=0)\n",
    "        rec  = recall_score(y, yp)\n",
    "        f1   = f1_score(y, yp)\n",
    "        tn, fp, fn, tp = confusion_matrix(y, yp).ravel()\n",
    "        rows.append({\"threshold\": float(t), \"precision\": prec, \"recall\": rec, \"f1\": f1, \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp})\n",
    "    return pd.DataFrame(rows).sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Example usage:\n",
    "# threshold_sweep(model, X_test_cnn, y_test).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb1fb534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>2272</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.980854</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.956210</td>\n",
       "      <td>2273</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.935574</td>\n",
       "      <td>0.954968</td>\n",
       "      <td>2269</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.954644</td>\n",
       "      <td>2274</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.954644</td>\n",
       "      <td>2274</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.954644</td>\n",
       "      <td>2274</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.969653</td>\n",
       "      <td>0.939776</td>\n",
       "      <td>0.954481</td>\n",
       "      <td>2265</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.972384</td>\n",
       "      <td>0.936975</td>\n",
       "      <td>0.954351</td>\n",
       "      <td>2267</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.982196</td>\n",
       "      <td>0.927171</td>\n",
       "      <td>0.953890</td>\n",
       "      <td>2274</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.475</td>\n",
       "      <td>0.966859</td>\n",
       "      <td>0.939776</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>2263</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        f1    tn  fp  fn   tp\n",
       "19      0.575   0.979472  0.935574  0.957020  2272  14  46  668\n",
       "20      0.600   0.980854  0.932773  0.956210  2273  13  48  666\n",
       "18      0.550   0.975182  0.935574  0.954968  2269  17  46  668\n",
       "22      0.650   0.982222  0.928571  0.954644  2274  12  51  663\n",
       "21      0.625   0.982222  0.928571  0.954644  2274  12  51  663\n",
       "23      0.675   0.982222  0.928571  0.954644  2274  12  51  663\n",
       "16      0.500   0.969653  0.939776  0.954481  2265  21  43  671\n",
       "17      0.525   0.972384  0.936975  0.954351  2267  19  45  669\n",
       "24      0.700   0.982196  0.927171  0.953890  2274  12  52  662\n",
       "15      0.475   0.966859  0.939776  0.953125  2263  23  43  671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Markdown to copy ---\n",
      "\n",
      "# Probability Threshold Tuning — CNN (1D) — HR Attrition\n",
      "\n",
      "We evaluated a grid of thresholds on the validation/test split to trade precision vs. recall.\n",
      "\n",
      "**Best F1** — threshold **0.58**  \n",
      "Precision **0.979**, Recall **0.936**, F1 **0.957**  \n",
      "Confusion matrix: TN=2272.0, FP=14.0, FN=46.0, TP=668.0\n",
      "\n",
      "**Best Recall (with precision ≥ 0.95)** — threshold **0.38**  \n",
      "Precision **0.953**, Recall **0.943**, F1 **0.948**  \n",
      "Confusion matrix: TN=2253.0, FP=33.0, FN=41.0, TP=673.0\n",
      "\n",
      "**How to use this:**  \n",
      "- Use the **Best F1** threshold if you want a balanced operating point.  \n",
      "- Use the **Best Recall** threshold when missing positives is costly; expect more false positives.  \n",
      "- Consider plotting precision–recall curves or sweeping a finer grid around these thresholds to refine the choice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Threshold Sweep + Auto Markdown Summary ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def threshold_sweep_keras(model, X, y, thresholds=np.linspace(0.1, 0.9, 33)):\n",
    "    \"\"\"Return metrics across thresholds for a Keras binary classifier (sigmoid output).\"\"\"\n",
    "    proba = model.predict(X, verbose=0).ravel()\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yp = (proba >= t).astype(int)\n",
    "        prec = precision_score(y, yp, zero_division=0)\n",
    "        rec  = recall_score(y, yp)\n",
    "        f1   = f1_score(y, yp)\n",
    "        tn, fp, fn, tp = confusion_matrix(y, yp).ravel()\n",
    "        rows.append({\n",
    "            \"threshold\": float(t),\n",
    "            \"precision\": prec, \"recall\": rec, \"f1\": f1,\n",
    "            \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"threshold\").reset_index(drop=True)\n",
    "\n",
    "def pick_thresholds(df_metrics, precision_floor=0.95):\n",
    "    \"\"\"Pick best-by-F1 and best-recall with precision >= floor (fallback to max recall if none).\"\"\"\n",
    "    best_f1_row = df_metrics.loc[df_metrics[\"f1\"].idxmax()].to_dict()\n",
    "\n",
    "    cand = df_metrics[df_metrics[\"precision\"] >= precision_floor]\n",
    "    if len(cand) == 0:\n",
    "        best_recall_row = df_metrics.loc[df_metrics[\"recall\"].idxmax()].to_dict()\n",
    "        recall_note = f\"(no threshold meets precision ≥ {precision_floor:.2f}; using max recall overall)\"\n",
    "    else:\n",
    "        best_recall_row = cand.loc[cand[\"recall\"].idxmax()].to_dict()\n",
    "        recall_note = f\"(with precision ≥ {precision_floor:.2f})\"\n",
    "    return best_f1_row, best_recall_row, recall_note\n",
    "\n",
    "def markdown_for_thresholds(model_name, best_f1_row, best_recall_row, recall_note):\n",
    "    \"\"\"Build a Markdown summary block for threshold selection.\"\"\"\n",
    "    def row_md(tag, r):\n",
    "        return (\n",
    "            f\"**{tag}** — threshold **{r['threshold']:.2f}**  \\n\"\n",
    "            f\"Precision **{r['precision']:.3f}**, Recall **{r['recall']:.3f}**, F1 **{r['f1']:.3f}**  \\n\"\n",
    "            f\"Confusion matrix: TN={r['tn']}, FP={r['fp']}, FN={r['fn']}, TP={r['tp']}\"\n",
    "        )\n",
    "\n",
    "    md = f\"\"\"# Probability Threshold Tuning — {model_name}\n",
    "\n",
    "We evaluated a grid of thresholds on the validation/test split to trade precision vs. recall.\n",
    "\n",
    "{row_md(\"Best F1\", best_f1_row)}\n",
    "\n",
    "{row_md(f\"Best Recall {recall_note}\", best_recall_row)}\n",
    "\n",
    "**How to use this:**  \n",
    "- Use the **Best F1** threshold if you want a balanced operating point.  \n",
    "- Use the **Best Recall** threshold when missing positives is costly; expect more false positives.  \n",
    "- Consider plotting precision–recall curves or sweeping a finer grid around these thresholds to refine the choice.\n",
    "\"\"\"\n",
    "    return md\n",
    "\n",
    "# --- Run on your current model and test set ---\n",
    "# Assumes `model`, `X_test_cnn`, `y_test` exist from previous cells.\n",
    "thresholds_df = threshold_sweep_keras(model, X_test_cnn, y_test, thresholds=np.linspace(0.1, 0.9, 33))\n",
    "\n",
    "# Choose thresholds (you can change precision_floor, e.g., 0.97 or 0.90)\n",
    "best_f1, best_rec, rec_note = pick_thresholds(thresholds_df, precision_floor=0.95)\n",
    "\n",
    "# Display a compact table head (optional)\n",
    "display(thresholds_df.sort_values(\"f1\", ascending=False).head(10))\n",
    "\n",
    "# Generate Markdown summary\n",
    "md_thresh = markdown_for_thresholds(\"CNN (1D) — HR Attrition\", best_f1, best_rec, rec_note)\n",
    "print(\"\\n--- Markdown to copy ---\\n\")\n",
    "print(md_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9b847",
   "metadata": {},
   "source": [
    "## Final Interpretation — Threshold Tuning (CNN 1D on HR Attrition)\n",
    "\n",
    "**Goal.** Choose a decision threshold that aligns model behavior with business priorities by trading precision (false-alarm rate) against recall (missed positives).\n",
    "\n",
    "### Key Operating Points (Test Set, N=3000)\n",
    "\n",
    "- **Default (t = 0.50)**  \n",
    "  Precision **0.978**, Recall **0.927**, F1 **0.952**  \n",
    "  Confusion matrix: **TN=2271, FP=15, FN=52, TP=662**  \n",
    "  Notes: Strong baseline; very few false positives, a small number of missed leavers.\n",
    "\n",
    "- **Best F1 (t ≈ 0.58)**  \n",
    "  Precision **0.979**, Recall **0.936**, F1 **0.957** (best)  \n",
    "  Confusion matrix: **TN=2272, FP=14, FN=46, TP=668**  \n",
    "  Notes: Slightly **higher F1** than the default by reducing both FP and FN. Overall accuracy ≈ **0.980**.  \n",
    "  → **Balanced choice** when precision and recall matter similarly.\n",
    "\n",
    "- **Best Recall with Precision ≥ 0.95 (t ≈ 0.38)**  \n",
    "  Precision **0.953**, Recall **0.943**, F1 **0.948**  \n",
    "  Confusion matrix: **TN=2253, FP=33, FN=41, TP=673**  \n",
    "  Notes: **Maximizes recall** under a precision floor; finds more leavers (+11 TP vs default) at the cost of more false alarms (+18 FP). Accuracy ≈ **0.975**.  \n",
    "  → **Safety-first choice** when missing a leaver is costly.\n",
    "\n",
    "### What This Means\n",
    "\n",
    "- Your model’s probability estimates are well-behaved: moving the threshold lets you **fine-tune** the FP/FN balance without collapsing precision.  \n",
    "- The **Best F1** threshold (≈0.58) is a robust, general-purpose operating point.  \n",
    "- If the business cost of a missed leaver (FN) is significantly higher than a false alarm (FP), prefer the **high-recall** threshold (≈0.38).\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Pick and document one primary threshold** for deployment (e.g., **0.58** for balanced performance).  \n",
    "2. **Scenario override:** in high-risk contexts (e.g., critical teams or high replacement cost), consider **0.38** to reduce missed leavers.  \n",
    "3. **Validate stability:** re-check thresholds with **k-fold or repeated CV**; report mean ± std of F1/recall at each operating point.  \n",
    "4. **Calibrate probabilities** (Platt or isotonic) if you need threshold stability across time or populations.  \n",
    "5. Monitor drift and **re-tune the threshold** periodically using fresh hold-out data.\n",
    "\n",
    "**Bottom line:**  \n",
    "Use **t ≈ 0.58** as the default, and **t ≈ 0.38** when recall must dominate. Both thresholds deliver excellent performance; choose based on business costs rather than a single metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
