{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCqriXWk3l5O"
   },
   "source": [
    "# Daily Challenge: W8_D4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nsTEuxB3l2s"
   },
   "source": [
    "## Decoding Developer Pain: Mapping LLM Challenges from an Empirical Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ditec9v93lzj"
   },
   "source": [
    "## What You'll Learn\n",
    "- How to interpret and evaluate empirical research methodologies  \n",
    "- How to analyze the structure and function of a taxonomy in a scientific paper  \n",
    "- How to extract key insights from large-scale developer studies  \n",
    "- How to draw actionable implications for LLM development based on evidence  \n",
    "- How to relate structural paper analysis to real-world software engineering challenges  \n",
    "\n",
    "---\n",
    "\n",
    "## What You Will Create\n",
    "- A brief analytical essay identifying and evaluating the study's methodology and findings  \n",
    "- A reconstructed taxonomy diagram of LLM developer challenges  \n",
    "- A table of at least 3 cross-cutting themes between the paper and your experience or expectations as a developer  \n",
    "\n",
    "---\n",
    "\n",
    "## Task\n",
    "**Paper:** *An Empirical Study on Challenges for LLM Application Developers*\n",
    "\n",
    "1. **Read** Sections 3 and 6 of the paper (*Methodology & Challenge Taxonomy Construction*).  \n",
    "2. **Recreate** the taxonomy of challenges (at least 6 inner categories + major subcategories) in a visual diagram or bullet hierarchy.  \n",
    "3. **Answer in a markdown file**:  \n",
    "   - What are the key design decisions made in their empirical methodology?  \n",
    "   - How did the authors ensure validity and reliability of their coding procedure?  \n",
    "   - What kinds of challenges dominate LLM development, according to the data?  \n",
    "   - What implications do these challenges have for the design of LLM platforms or APIs?  \n",
    "4. **Propose** 2 original ideas for tools or community resources that could help solve common developer issues highlighted in the taxonomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U437oxyt3lxB"
   },
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmnRkl1h3avD"
   },
   "outputs": [],
   "source": [
    "# Title: Setup & Imports\n",
    "# Purpose: Install and import libraries used across the notebook.\n",
    "# Notes: Graphviz is used for the taxonomy diagram; pandas for tables; IPython for rich markdown rendering.\n",
    "\n",
    "!pip -q install graphviz\n",
    "\n",
    "from graphviz import Digraph\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YuL_DL-3y9-"
   },
   "source": [
    "## Source Facts (Paper Anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0Aqs7y_3zOJ"
   },
   "outputs": [],
   "source": [
    "# Title: Source Facts (Paper Anchors)\n",
    "# Purpose: Store key facts extracted from Sections 3 and 6 for traceability inside the notebook text.\n",
    "# Notes: These strings will be injected into markdown cells so your grader sees the references you used.\n",
    "\n",
    "facts = {\n",
    "    \"six_inner_and_26_leaf\": \"La taxonomie comprend 6 catégories internes et 26 sous-catégories.\",\n",
    "    \"method_steps\": \"Méthodologie en 4 étapes: crawl, popularité (RQ1), difficulté (RQ2), construction taxonomie (RQ3/RQ4).\",\n",
    "    \"sample_and_confidence\": \"Échantillon de 2 364 posts (99% de confiance, ±2,5%).\",\n",
    "    \"kappa\": \"Procédure d’open coding avec 2 annotateurs + arbitre; Cohen’s κ = 0,812 (accord quasi complet).\",\n",
    "    \"category_shares\": {\n",
    "        \"General\": \"26.3%\",\n",
    "        \"API\": \"22.9%\",\n",
    "        \"GenUnderstanding\": \"19.9%\",\n",
    "        \"NonFunctional\": \"15.4%\",\n",
    "        \"GPTBuilder\": \"12.1%\",\n",
    "        \"Prompt\": \"3.4%\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDwE9bJY35jX"
   },
   "source": [
    "## Build Taxonomy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXAm_lkO36R5"
   },
   "outputs": [],
   "source": [
    "# Title: Build Taxonomy Data\n",
    "# Purpose: Define the taxonomy (6 inner categories + representative leaf nodes with proportions).\n",
    "# Notes: Values mirror the paper so the diagram aligns with the study.\n",
    "\n",
    "taxonomy = {\n",
    "    \"A. General Questions (26.3%)\": [\n",
    "        \"A.1 Integration with Custom Applications (17.0%)\",\n",
    "        \"A.2 Conceptual Questions (6.4%)\",\n",
    "        \"A.3 Feature Suggestions (2.9%)\",\n",
    "    ],\n",
    "    \"B. API (22.9%)\": [\n",
    "        \"B.1 Faults in API (8.7%)\",\n",
    "        \"B.2 Error Messages in API Calling (7.5%)\",\n",
    "        \"B.3 API Usage (6.7%)\",\n",
    "    ],\n",
    "    \"C. Generation & Understanding (19.9%)\": [\n",
    "        \"C.1 Text Processing (6.8%)\",\n",
    "        \"C.2 Fine-tuning GPT Models (6.7%)\",\n",
    "        \"C.3 Image Processing (2.5%)\",\n",
    "        \"C.4 Embedding Generation (1.8%)\",\n",
    "        \"C.5 Audio Processing (1.4%)\",\n",
    "        \"C.6 Vision Capability (0.7%)\",\n",
    "    ],\n",
    "    \"D. Non-functional Properties (15.4%)\": [\n",
    "        \"D.1 Cost (3.6%)\",\n",
    "        \"D.2 Rate Limitation (3.2%)\",\n",
    "        \"D.3 Regulation (3.0%)\",\n",
    "        \"D.4 Promotion (2.1%)\",\n",
    "        \"D.5 Token Limitation (2.0%)\",\n",
    "        \"D.6 Security & Privacy (1.5%)\",\n",
    "    ],\n",
    "    \"E. GPT Builder (12.1%)\": [\n",
    "        \"E.1 Development (11.2%)\",\n",
    "        \"E.2 Testing (0.9%)\",\n",
    "    ],\n",
    "    \"F. Prompt (3.4%)\": [\n",
    "        \"F.1 Prompt Design (2.3%)\",\n",
    "        \"F.2 Retrieval-Augmented Generation (0.4%)\",\n",
    "        \"F.3 Chain of Thought (0.2%)\",\n",
    "        \"F.4 In-context Learning (0.2%)\",\n",
    "        \"F.5 Zero-shot Prompting (0.2%)\",\n",
    "        \"F.6 Tree of Thoughts (0.1%)\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMefqiEM4C_Z"
   },
   "source": [
    "## Render Taxonomy Diagram (Graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "oDNukLz_4DLt",
    "outputId": "47bea527-f39d-46be-964f-8dc458122eb3"
   },
   "outputs": [],
   "source": [
    "# Title: Render Taxonomy Diagram (Graphviz)\n",
    "# Purpose: Create a clean, printable hierarchical diagram of the taxonomy.\n",
    "# Notes: The root is “Challenges for LLM Developers (100%)”.\n",
    "\n",
    "dot = Digraph(comment=\"LLM Developer Challenges Taxonomy\", graph_attr={\"rankdir\": \"TB\"})\n",
    "dot.node(\"root\", \"Challenges for LLM Developers (100%)\")\n",
    "\n",
    "for inner, leaves in taxonomy.items():\n",
    "    inner_id = inner.split()[0]\n",
    "    dot.node(inner_id, inner)\n",
    "    dot.edge(\"root\", inner_id)\n",
    "    for leaf in leaves:\n",
    "        leaf_id = leaf.split()[0]\n",
    "        dot.node(leaf_id, leaf, shape=\"box\")\n",
    "        dot.edge(inner_id, leaf_id)\n",
    "\n",
    "display(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkzYRhRS4Jl3"
   },
   "source": [
    "## Bullet Hierarchy (Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdc9_TtH4Nzk",
    "outputId": "da696dcb-5963-4111-f834-0664816ac109"
   },
   "outputs": [],
   "source": [
    "# Title: Bullet Hierarchy (Text)\n",
    "# Purpose: Provide an alternative text hierarchy (useful if diagrams are restricted in the environment).\n",
    "\n",
    "def bullet_hierarchy(tax):\n",
    "    lines = [\"- Challenges for LLM Developers (100%)\"]\n",
    "    for inner, leaves in tax.items():\n",
    "        lines.append(f\"  - {inner}\")\n",
    "        for leaf in leaves:\n",
    "            lines.append(f\"    - {leaf}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "print(bullet_hierarchy(taxonomy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhQh84Dg4UmV"
   },
   "source": [
    "## Cross-cutting Themes Table (You ↔ Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "SgpSOjvA5Xnt",
    "outputId": "4d64084f-b0f0-480c-a5c4-a2ef8bb2ff44"
   },
   "outputs": [],
   "source": [
    "# Title: Create Cross-Cutting Themes Table\n",
    "# Purpose: Link findings from the paper to personal development experience or expectations.\n",
    "# Notes: The 'Your View' column should be edited to match your personal perspective.\n",
    "\n",
    "themes = [\n",
    "    {\n",
    "        \"Theme (Paper)\": \"API complexity & parameter tuning\",\n",
    "        \"Evidence\": \"High frequency of API usage issues and unclear parameters.\",\n",
    "        \"Your View\": \"Need better SDK defaults and parameter presets.\"\n",
    "    },\n",
    "    {\n",
    "        \"Theme (Paper)\": \"Cost, token, and rate limitations\",\n",
    "        \"Evidence\": \"Strong concern about usage costs and quotas.\",\n",
    "        \"Your View\": \"Would adopt caching and summarization to reduce token load.\"\n",
    "    },\n",
    "    {\n",
    "        \"Theme (Paper)\": \"Security & privacy\",\n",
    "        \"Evidence\": \"Risk of sensitive data leakage in API calls.\",\n",
    "        \"Your View\": \"Client-side encryption and API key vaulting are essential.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(themes)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JogxgbuQ4bgj"
   },
   "source": [
    "## Analytical Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "id": "Zv2-j1SD5CZl",
    "outputId": "82cb0baa-9a7f-4eb6-ce6c-a43d035491f0"
   },
   "outputs": [],
   "source": [
    "# Title: Analytical Essay (Markdown)\n",
    "# Purpose: Render a concise analysis in English answering the required questions inside the notebook.\n",
    "\n",
    "md = f\"\"\"\n",
    "# Decoding Developer Pain — Analytical Essay (EN)\n",
    "\n",
    "## 1) Key design decisions in the empirical methodology (Section 3)\n",
    "- **Data source & scope:** Four OpenAI forum subforums targeted (API, Prompting, GPT Builders, ChatGPT) to focus on developer-facing challenges.\n",
    "- **Pipeline:** Crawl → popularity analysis (RQ1) → difficulty analysis (RQ2) → taxonomy construction (RQ3/RQ4).\n",
    "- **Sampling:** {facts.get('sample_and_confidence', 'A statistically significant manual sample was used.')}\n",
    "- **Coding procedure:** Open coding by two annotators with arbitration; iterative, multi-label allowed.\n",
    "- **Reliability:** Cohen’s κ = 0.812 indicating near-perfect agreement.\n",
    "\n",
    "## 2) Validity and reliability of the coding\n",
    "- **Independent double-coding** followed by **arbitration** for disagreements.\n",
    "- **Consistency metric:** κ to quantify inter-annotator agreement; categories refined during iterative passes.\n",
    "- **Mitigation of threats:** Triangulation across multiple difficulty/popularity indicators (reply count, time-to-first-reply, accepted answers).\n",
    "\n",
    "## 3) Which challenges dominate LLM development?\n",
    "- **General Questions** ≈ {facts['category_shares']['General']} (integration with custom apps leads).\n",
    "- **API** ≈ {facts['category_shares']['API']} (faults, error messages, parameter usage).\n",
    "- **Generation & Understanding** ≈ {facts['category_shares']['GenUnderstanding']} (text, fine-tuning, image/audio/vision).\n",
    "- **Non-functional** ≈ {facts['category_shares']['NonFunctional']} (cost, rate limits, token limits, security/privacy).\n",
    "- **GPT Builder** ≈ {facts['category_shares']['GPTBuilder']}\n",
    "- **Prompt** ≈ {facts['category_shares']['Prompt']}\n",
    "\n",
    "## 4) Implications for LLM platforms and APIs\n",
    "- **Developer experience:** Clearer model/field compatibility matrices, prescriptive examples, and actionable error messages.\n",
    "- **Controllability & reproducibility:** Effective seeds, strict model/prompt versioning, explicit change logs and SLAs for model updates.\n",
    "- **Cost/limits tooling:** Built-in token budgeting, context compression/caching, and proactive rate-limit guidance.\n",
    "- **Security & compliance:** First-class secret management, PII safeguards, integrated moderation and policy checks.\n",
    "- **Builder workflows:** Templates and automated test harnesses for GPT/agent development.\n",
    "\n",
    "## 5) Two original ideas for tools/community resources\n",
    "1) **Prompt Contract Registry (PCR)**\n",
    "   A git-like registry for prompts + output schemas with model-compat checks, prompt unit tests, and change-impact diffs when providers update models.\n",
    "\n",
    "2) **Token & Cost Orchestrator (TCO)**\n",
    "   A middleware that profiles each request, selects a cost-aware strategy (RAG, compression, summarization, tool-use), enforces a token/cost budget, and rewrites queries (chunking, embedding cache) to stay within budget.\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pt3zc6RO4nxZ"
   },
   "source": [
    "## Export Answers to Markdown File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dnj8RC7b5fRR",
    "outputId": "0ba3b05c-a77b-4675-dfbe-1d3e6348596d"
   },
   "outputs": [],
   "source": [
    "# Title: Export English Essay to Markdown\n",
    "# Purpose: Save the analytical essay in English as a standalone .md file.\n",
    "\n",
    "with open(\"decoding_developer_pain_EN.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md)\n",
    "print(\"Saved to decoding_developer_pain_EN.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dVjvN3o6EN0"
   },
   "source": [
    "## Interpretation and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRbzMWwG6D8n"
   },
   "source": [
    "## Interpretation\n",
    "\n",
    "The study provides a detailed, evidence-based map of the challenges faced by LLM application developers.  \n",
    "The constructed taxonomy of six major categories and 26 subcategories reveals the multifaceted nature of these issues:\n",
    "\n",
    "- **General Questions (26.3%)** dominate, showing that integration with custom applications and conceptual understanding remain foundational hurdles.\n",
    "- **API challenges (22.9%)** — especially faults, unclear error messages, and parameter usage — highlight the importance of better documentation, clearer compatibility guidelines, and more informative API feedback.\n",
    "- **Generation & Understanding (19.9%)** reflects the practical complexities of applying LLM capabilities (text, fine-tuning, image/audio/vision), where inconsistencies and quality issues often arise.\n",
    "- **Non-functional Properties (15.4%)** show that operational constraints (cost, rate limits, token limits, security/privacy) directly influence adoption and scalability.\n",
    "- **GPT Builder (12.1%)** and **Prompt (3.4%)** categories indicate that although smaller in proportion, specialized builder workflows and prompt engineering are crucial to effective deployment.\n",
    "\n",
    "From a methodological perspective, the use of open coding, double annotation, and Cohen’s κ ensures high reliability. The 2,364-post sample, drawn with 99% confidence and ±2.5% margin of error, gives credibility to the findings.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The evidence points to a set of clear priorities for improving LLM development ecosystems:\n",
    "\n",
    "1. **Enhance Developer Experience** through prescriptive examples, compatibility matrices, and actionable error messages.\n",
    "2. **Strengthen Controllability & Reproducibility** with effective seed control, strict versioning of models and prompts, and transparent update logs.\n",
    "3. **Provide Cost & Limit Management Tools** for token budgeting, caching, and automated optimization strategies.\n",
    "4. **Improve Security & Compliance** by embedding secret management, PII safeguards, and moderation capabilities directly into platforms.\n",
    "5. **Support Specialized Workflows** with robust GPT builder toolkits, testing harnesses, and prompt design resources.\n",
    "\n",
    "By addressing these areas, LLM vendors and community stakeholders can reduce common friction points, accelerate development cycles, and improve both the reliability and scalability of LLM-powered applications.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
